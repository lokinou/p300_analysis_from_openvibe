{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short ERP Analysis from OpenVibe data converted to gdf\n",
    "Data was converted to gdf using openvibe-convert.cmd\n",
    "- First step is to rename and filter the annotations from openvibe\n",
    "- translate the annotations into markers\n",
    "- create epochs\n",
    "- process epochs\n",
    "- plot ERP\n",
    "- (?) a bit of statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "#%matplotlib ipympl\n",
    "import os\n",
    "import mne\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove me\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf, read_raw_brainvision\n",
    "from mne.time_frequency import tfr_multitaper\n",
    "from mne.stats import permutation_cluster_1samp_test as pcluster_test\n",
    "from mne.viz.utils import center_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "apply_infinite_reference = True\n",
    "apply_CSD = False  # use Current Source Density (spatial filter)\n",
    "apply_ASR = False  # use Artifact Subspace Reconstruction (artifact removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\BCI\\dev\\p300_analysis_from_openvibe\\data_calib-024-2021-05-26_17_04_59.gdf\n"
     ]
    }
   ],
   "source": [
    "data_dir=r\"C:\\BCI\\dev\\p300_analysis_from_openvibe\"\n",
    "os.path.exists(data_dir)\n",
    "fnames = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".gdf\"):\n",
    "        fnames.append(os.path.join(data_dir, file))\n",
    "        print(os.path.join(data_dir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load gdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\BCI\\dev\\p300_analysis_from_openvibe\\data_calib-024-2021-05-26_17_04_59.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 50687  =      0.000 ...   197.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d0f71234aaee>:2: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
      "  raws = [mne.io.read_raw_gdf(f, preload=True) for f in [fnames[0]]]\n"
     ]
    }
   ],
   "source": [
    "# load and preprocess data ####################################################\n",
    "raws = [mne.io.read_raw_gdf(f, preload=True) for f in [fnames[0]]]\n",
    "#raw = concatenate_raws(raws)\n",
    "raw = raws[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Channel 1',\n",
       " 'Channel 2',\n",
       " 'Channel 3',\n",
       " 'Channel 4',\n",
       " 'Channel 5',\n",
       " 'Channel 6',\n",
       " 'Channel 7',\n",
       " 'Channel 8']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['ch_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%  md\n"
    }
   },
   "source": [
    "### Todo: rereference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fz', 'Cz', 'P3', 'Pz', 'P4', 'PO7', 'PO8', 'Oz']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 8 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>256.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>128.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>data_calib-024-2021-05-26_17_04_59.gdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:03:17 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawGDF | data_calib-024-2021-05-26_17_04_59.gdf, 8 x 50688 (198.0 s), ~3.1 MB, data loaded>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define channel names\n",
    "cname = ['Fz', 'Cz', 'P3', 'Pz', 'P4', 'PO7', 'PO8', 'Oz']\n",
    "if len(raw.info['ch_names'])>8:\n",
    "    cname.extend([\"ch{}\".format(i) for i in range(9,16+1)])\n",
    "print(cname)\n",
    "cname_map = dict(zip(raw.info['ch_names'], cname))\n",
    "# define channel types\n",
    "types = list(itertools.repeat('eeg', 8))\n",
    "if len(raw.info['ch_names'])>8:\n",
    "    types.extend(list(itertools.repeat('misc', 8)))\n",
    "type_map = dict(zip(cname, types))\n",
    "\n",
    "# rename and pick eeg\n",
    "raw.rename_channels(cname_map, allow_duplicates=False)\n",
    "raw.set_channel_types(type_map)\n",
    "raw.pick_types(eeg=True, misc=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the 10-05 montage defining electrode positions. This will allow topoplots and CSD processing to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "raw = raw.set_montage(montage, match_case=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate an infinite reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-9f85417f30f4>:3: RuntimeWarning: Only 8 head digitization points of the specified kinds (\"eeg\", \"extra\",), fitting may be inaccurate\n",
      "  sphere = mne.make_sphere_model('auto', 'auto', raw.info)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted sphere radius:         95.0 mm\n",
      "Origin head coordinates:      0.9 5.9 51.9 mm\n",
      "Origin device coordinates:    0.9 5.9 51.9 mm\n",
      "\n",
      "Equiv. model fitting -> RV = 0.00348816 %\n",
      "mu1 = 0.944717    lambda1 = 0.13715\n",
      "mu2 = 0.667488    lambda2 = 0.683746\n",
      "mu3 = -0.270376    lambda3 = -0.0105261\n",
      "Set up EEG sphere model with scalp radius    95.0 mm\n",
      "\n",
      "Sphere                : origin at (0.9 5.9 51.9) mm\n",
      "              radius  : 85.5 mm\n",
      "grid                  : 15.0 mm\n",
      "mindist               : 5.0 mm\n",
      "Exclude               : 30.0 mm\n",
      "\n",
      "Setting up the sphere...\n",
      "Surface CM = (   0.9    5.9   51.9) mm\n",
      "Surface fits inside a sphere with radius   85.5 mm\n",
      "Surface extent:\n",
      "    x =  -84.6 ...   86.5 mm\n",
      "    y =  -79.7 ...   91.4 mm\n",
      "    z =  -33.6 ...  137.5 mm\n",
      "Grid extent:\n",
      "    x =  -90.0 ...   90.0 mm\n",
      "    y =  -90.0 ...  105.0 mm\n",
      "    z =  -45.0 ...  150.0 mm\n",
      "2548 sources before omitting any.\n",
      "742 sources after omitting infeasible sources not within 30.0 - 85.5 mm.\n",
      "615 sources remaining after excluding the sources outside the surface and less than    5.0 mm inside.\n",
      "Adjusting the neighborhood info.\n",
      "Source space : MRI voxel -> MRI (surface RAS)\n",
      "     0.015000  0.000000  0.000000     -90.00 mm\n",
      "     0.000000  0.015000  0.000000     -90.00 mm\n",
      "     0.000000  0.000000  0.015000     -45.00 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "Source space          : <SourceSpaces: [<discrete, n_used=615>] MRI (surface RAS) coords, ~389 kB>\n",
      "MRI -> head transform : identity\n",
      "Measurement data      : instance of Info\n",
      "Sphere model      : origin at [0.00094219 0.00585968 0.05191565] mm\n",
      "Standard field computations\n",
      "Do computations in head coordinates\n",
      "Free source orientations\n",
      "\n",
      "Read 1 source spaces a total of 615 active source locations\n",
      "\n",
      "Coordinate transformation: MRI (surface RAS) -> head\n",
      "     1.000000  0.000000  0.000000       0.00 mm\n",
      "     0.000000  1.000000  0.000000       0.00 mm\n",
      "     0.000000  0.000000  1.000000       0.00 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "\n",
      "Read   8 EEG channels from info\n",
      "Head coordinate coil definitions created.\n",
      "Source spaces are now in head coordinates.\n",
      "\n",
      "Using the sphere model.\n",
      "\n",
      "Using the equivalent source approach in the homogeneous sphere for EEG\n",
      "Computing EEG at 615 source locations (free orientations)...\n",
      "\n",
      "Finished.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying REST reference.\n",
      "Applying a custom EEG reference.\n",
      "    8 out of 8 channels remain after picking\n"
     ]
    }
   ],
   "source": [
    "if apply_infinite_reference:\n",
    "    raw.del_proj()  # remove our average reference projector first\n",
    "    sphere = mne.make_sphere_model('auto', 'auto', raw.info)\n",
    "    src = mne.setup_volume_source_space(sphere=sphere, exclude=30., pos=15.)\n",
    "    forward = mne.make_forward_solution(raw.info, trans=None, src=src, bem=sphere)\n",
    "    raw_rest = raw.copy().set_eeg_reference('REST', forward=forward)\n",
    "\n",
    "    for title, _raw in zip(['Original', 'REST (∞)'], [raw, raw_rest]):\n",
    "        fig = _raw.plot(n_channels=len(raw), scalings=dict(eeg=5e-5))\n",
    "        # make room for title\n",
    "        fig.subplots_adjust(top=0.9)\n",
    "        fig.suptitle('{} reference'.format(title), size='xx-large', weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass the signal\n",
    "Removes noise and drift from the EEG signal by applying a infinite impulse response (two-pass) filter between .5 and 40Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 40.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>11 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 8 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>256.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.50 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>40.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>data_calib-024-2021-05-26_17_04_59.gdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:03:17 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawGDF | data_calib-024-2021-05-26_17_04_59.gdf, 8 x 50688 (198.0 s), ~3.1 MB, data loaded>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.filter(.5, 40, fir_window='hann', method='iir')\n",
    "raw.notch_filter(50)  # removes 50Hz noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the filtered signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.plot()\n",
    "apply_CSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply current source density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_CSD:\n",
    "    raw_csd = mne.preprocessing.compute_current_source_density(raw)\n",
    "    raw = raw_csd\n",
    "    raw_csd.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifact Subspace Reconstruction fitting and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_ASR:\n",
    "    #!pip install meegkit pymanopt\n",
    "    from meegkit.asr import ASR\n",
    "    fs = int(raw.info[\"sfreq\"])  # sampling frequency\n",
    "    method='riemann'  # if error, use 'euclid' -> actually the case\n",
    "    window_s=.5  # .5 sec window of analysis\n",
    "    data_interval_s  = None # (begin, end) in sec of the training sample\n",
    "    estimator='lwf'  #leave blank if using euclidian mode \n",
    "\n",
    "    # define the ASR model using riemannian method\n",
    "    #asr_model = ASR(sfreq=fs, method=method, win_len=window_s, estimator=estimator)\n",
    "\n",
    "    # if failing (after trying twice. SVD error occurs for no reason sometimes)\n",
    "    asr_model = ASR(sfreq=fs, method=\"euclid\", win_len=window_s)\n",
    "\n",
    "    # The best would be to choose another recording during the same session to train the model without overfitting\n",
    "    data = raw._data  # the numpy array with data is stored in the _data variable\n",
    "\n",
    "    # Select a time interval for training data\n",
    "    train_idx = None\n",
    "    if data_interval_s is not None:\n",
    "        train_idx = np.arange(data_interval_s[0] * fs, data_interval_s[1] * fs, dtype=int)\n",
    "    # otherwise select the whole training set\n",
    "    else:\n",
    "        train_idx = np.arange(0, data.shape[1])\n",
    "\n",
    "    train_data = data[:, train_idx]\n",
    "    print('Training on samples of size {}'.format(train_data.shape))\n",
    "\n",
    "    # fir the ASR model with data intervals\n",
    "    _, sample_mask = asr_model.fit(train_data)\n",
    "    print('Model trained')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the current dataset\n",
    "Please check whether using this artifact filtering method increases signal to noise ratio rather than reducing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_ASR:\n",
    "    clean =  asr_model.transform(raw._data)\n",
    "\n",
    "    display_asr_results = True\n",
    "    display_window_s = 15  # \n",
    "\n",
    "    if display_asr_results:  #\n",
    "        data_p = raw._data[0:fs*display_window_s]  # reshape to (n_chans, n_times)\n",
    "        clean_p = clean[0:fs*display_window_s]\n",
    "\n",
    "        ###############################################################################\n",
    "        # Plot the results\n",
    "        # -----------------------------------------------------------------------------\n",
    "        #\n",
    "        # Data was trained on a 40s window from 5s to 45s onwards (gray filled area).\n",
    "        # The algorithm then removes portions of this data with high amplitude\n",
    "        # artifacts before running the calibration (hatched area = good).\n",
    "        nb_ch_disp = 5\n",
    "        times = np.arange(data_p.shape[-1]) / fs\n",
    "        f, ax = plt.subplots(nb_ch_disp, sharex=True, figsize=(32, 16))\n",
    "        for i in range(nb_ch_disp):\n",
    "            # ax[i].fill_between(train_idx / fs, 0, 1, color='grey', alpha=.3,\n",
    "            #                   transform=ax[i].get_xaxis_transform(),\n",
    "            #                   label='calibration window')\n",
    "            # ax[i].fill_between(train_idx / fs, 0, 1, where=sample_mask.flat,\n",
    "            #                   transform=ax[i].get_xaxis_transform(),\n",
    "            #                   facecolor='none', hatch='...', edgecolor='k',\n",
    "            #                   label='selected window')\n",
    "            ax[i].plot(times, data_p[i], lw=.5, label='before ASR')\n",
    "            ax[i].plot(times, clean_p[i], label='after ASR', lw=.5)\n",
    "            # ax[i].plot(times, raw[i]-clean[i], label='Diff', lw=.5)\n",
    "            # ax[i].set_ylim([-50, 50])\n",
    "            ax[i].set_ylabel(f'ch{i}')\n",
    "            ax[i].set_yticks([])\n",
    "        ax[i].set_xlabel('Time (s)')\n",
    "        ax[0].legend(fontsize='small', bbox_to_anchor=(1.04, 1), borderaxespad=0)\n",
    "        plt.subplots_adjust(hspace=0, right=0.75)\n",
    "        plt.suptitle('Before/after ASR')\n",
    "        plt.show()\n",
    "    raw.data_ = clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dont forget to use the cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text annotations (i.e. unprocessed events) into events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          onset  duration description\n",
      "0    1970-01-01 00:00:43.785156  0.003906           0\n",
      "1    1970-01-01 00:00:43.789062  0.003906       32773\n",
      "2    1970-01-01 00:00:43.789062  0.003906       33038\n",
      "3    1970-01-01 00:00:43.789062  0.003906       33286\n",
      "4    1970-01-01 00:00:43.847656  0.003906       32779\n",
      "...                         ...       ...         ...\n",
      "2807 1970-01-01 00:03:15.339844  0.003906       32780\n",
      "2808 1970-01-01 00:03:15.339844  0.003906       33028\n",
      "2809 1970-01-01 00:03:15.339844  0.003906       33286\n",
      "2810 1970-01-01 00:03:15.402344  0.003906       32779\n",
      "2811 1970-01-01 00:03:15.535156  0.003906       32780\n",
      "\n",
      "[2812 rows x 3 columns]\n",
      "Displaying all annotations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 32773,\n",
       " 32774,\n",
       " 32779,\n",
       " 32780,\n",
       " 33025,\n",
       " 33026,\n",
       " 33027,\n",
       " 33028,\n",
       " 33029,\n",
       " 33030,\n",
       " 33031,\n",
       " 33032,\n",
       " 33033,\n",
       " 33034,\n",
       " 33035,\n",
       " 33036,\n",
       " 33037,\n",
       " 33038,\n",
       " 33285,\n",
       " 33286]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "print(raw.annotations.to_data_frame())\n",
    "df = raw.annotations.to_data_frame()\n",
    "print('Displaying all annotations')\n",
    "annot_codes = [np.int64(n) for n in np.unique(df['description'])]\n",
    "annot_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These annotations seem to relate to hex codes. OpenViBE definitions can be found on [OpenViBE's website](http://openvibe.inria.fr/stimulation-codes/). Let's parse the copypasted list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tr_sim= ''\n",
    "pat_extract= re.compile('^([^ ]+)[ ]+0x[0-9A-Fa-f]+[ \\/]+([0-9]+)')\n",
    "#OVTK_GDF_125_Watt                                     0x585       //  1413\n",
    "k_stim = []\n",
    "k_stim_int = []\n",
    "v_stim = []\n",
    "\n",
    "# read and convert annotations\n",
    "with open(r'.\\ov_stims.txt', 'r') as fd:\n",
    "    for line in fd.readlines():\n",
    "        m = pat_extract.match(line)\n",
    "        v, k = m.groups()\n",
    "        k_stim.append(k)\n",
    "        k_stim_int.append(int(k))\n",
    "        v_stim.append(v)\n",
    "\n",
    "# format dict and list\n",
    "stim_map = dict(zip(k_stim_int, v_stim))\n",
    "stim_map_inv = dict(zip(v_stim, k_stim))\n",
    "\n",
    "stim_tup = list(zip(k_stim_int, v_stim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataframe of the stimuli in common between both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coden</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>33025</td>\n",
       "      <td>OVTK_StimulationId_Label_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>33026</td>\n",
       "      <td>OVTK_StimulationId_Label_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>33027</td>\n",
       "      <td>OVTK_StimulationId_Label_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>33028</td>\n",
       "      <td>OVTK_StimulationId_Label_04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>33029</td>\n",
       "      <td>OVTK_StimulationId_Label_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>33030</td>\n",
       "      <td>OVTK_StimulationId_Label_06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>33031</td>\n",
       "      <td>OVTK_StimulationId_Label_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>33032</td>\n",
       "      <td>OVTK_StimulationId_Label_08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>33033</td>\n",
       "      <td>OVTK_StimulationId_Label_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>33034</td>\n",
       "      <td>OVTK_StimulationId_Label_0A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>33035</td>\n",
       "      <td>OVTK_StimulationId_Label_0B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>33036</td>\n",
       "      <td>OVTK_StimulationId_Label_0C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>33037</td>\n",
       "      <td>OVTK_StimulationId_Label_0D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>33038</td>\n",
       "      <td>OVTK_StimulationId_Label_0E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>33286</td>\n",
       "      <td>OVTK_StimulationId_NonTarget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>OVTK_StimulationId_Number_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>33285</td>\n",
       "      <td>OVTK_StimulationId_Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>32773</td>\n",
       "      <td>OVTK_StimulationId_TrialStart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>32774</td>\n",
       "      <td>OVTK_StimulationId_TrialStop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>32779</td>\n",
       "      <td>OVTK_StimulationId_VisualStimulationStart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>32780</td>\n",
       "      <td>OVTK_StimulationId_VisualStimulationStop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coden                                       desc\n",
       "125  33025                OVTK_StimulationId_Label_01\n",
       "126  33026                OVTK_StimulationId_Label_02\n",
       "127  33027                OVTK_StimulationId_Label_03\n",
       "128  33028                OVTK_StimulationId_Label_04\n",
       "129  33029                OVTK_StimulationId_Label_05\n",
       "130  33030                OVTK_StimulationId_Label_06\n",
       "131  33031                OVTK_StimulationId_Label_07\n",
       "132  33032                OVTK_StimulationId_Label_08\n",
       "133  33033                OVTK_StimulationId_Label_09\n",
       "134  33034                OVTK_StimulationId_Label_0A\n",
       "135  33035                OVTK_StimulationId_Label_0B\n",
       "136  33036                OVTK_StimulationId_Label_0C\n",
       "137  33037                OVTK_StimulationId_Label_0D\n",
       "138  33038                OVTK_StimulationId_Label_0E\n",
       "381  33286               OVTK_StimulationId_NonTarget\n",
       "382      0               OVTK_StimulationId_Number_00\n",
       "420  33285                  OVTK_StimulationId_Target\n",
       "425  32773              OVTK_StimulationId_TrialStart\n",
       "426  32774               OVTK_StimulationId_TrialStop\n",
       "429  32779  OVTK_StimulationId_VisualStimulationStart\n",
       "430  32780   OVTK_StimulationId_VisualStimulationStop"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(stim_tup)\n",
    "df.columns = ['coden', 'desc']\n",
    "df[[c in annot_codes for c in df.coden]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this table, lets locate and save the codes for Target and Non-Target and give them the following values: target=1 and non-target=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'33286':0, '33285':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can convert annotations into events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['33285', '33286']\n",
      "Found 701 events\n"
     ]
    }
   ],
   "source": [
    "events, _ = mne.events_from_annotations(raw, event_id=target_map)\n",
    "print(\"Found {} events\".format(len(events[:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the channels to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_backup = raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick all channels\n",
    "picks = mne.pick_channels(raw.info[\"ch_names\"], include=[])\n",
    "picks\n",
    "raw.plot_sensors(show_names=True)\n",
    "fig = raw.plot_sensors('3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create epochs for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Duplicate found at sample(s) [30536]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "events[:, 0]\n",
    "a = np.array(events[:, 0])\n",
    "dups = [item for item, count in Counter(a).items() if count > 1]\n",
    "if dups:\n",
    "    print(\"WARNING: Duplicate found at sample(s) {}\".format(dups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Not setting metadata\n",
      "700 matching events found\n",
      "Setting baseline interval to [-0.5, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 700 events and 283 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "event_ids = dict(NonTarget=0, Target=1) \n",
    "epochs = mne.Epochs(raw, events, event_id=event_ids, tmin=-0.5, tmax=0.6, event_repeated='drop', picks = ['eeg'],\n",
    "                    preload=True)\n",
    "fig = epochs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### todo: reject some events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    reject_criteria = dict(eeg=100e-6,  # 100 µV\n",
    "                       eog=200e-6)  # 200 µV\n",
    "    _ = epochs.drop_bad(reject=reject_criteria)\n",
    "    epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average the epochs of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_nt = epochs['NonTarget'].average()\n",
    "l_target = epochs['Target'].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1)\n",
    "fig1 = l_target.plot(spatial_colors=True, axes=ax[0])\n",
    "fig2 = l_nt.plot(spatial_colors=True, axes=ax[1])\n",
    "# Add title\n",
    "fig.suptitle(\"Target(top) - Non-Target(bottom)\")\n",
    "# Fix font spacing\n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_kw = dict(width_ratios=[1,1,1,.15], wspace=0.5,\n",
    "               hspace=0.5,height_ratios=[1,1])\n",
    "                         #hspace=0.5, height_ratios=[1, 2])\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, gridspec_kw=spec_kw)\n",
    "l_target.plot_topomap(times=[-0.2, 0.1, 0.4], average=0.05, axes=ax[0,:])\n",
    "l_nt.plot_topomap(times=[-0.2, 0.1, 0.4], average=0.05, axes=ax[1,:])\n",
    "fig.suptitle(\"Target(top) - Non-Target(bottom)\")\n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n"
     ]
    }
   ],
   "source": [
    "l_target.plot_joint()\n",
    "plt.gcf().canvas.set_window_title('Target joint plot')\n",
    "l_nt.plot_joint()\n",
    "plt.gcf().canvas.set_window_title('Non-Target joint plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 6 channels, truncating title ...\n",
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 800x600 with 1 Axes>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
    "               Target=list(epochs['Target'].iter_evoked()))\n",
    "#picks = [f'eeg{n}' for n in range(10, 15)]\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=picks, combine='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting channel 1\n",
      "plotting channel 2\n",
      "plotting channel 3\n",
      "plotting channel 4\n",
      "plotting channel 5\n",
      "plotting channel 6\n",
      "plotting channel 7\n",
      "plotting channel 8\n",
      "plotting averaged channels\n",
      "More than 6 channels, truncating title ...\n",
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n"
     ]
    }
   ],
   "source": [
    "nb_chans = epochs['Target']._data.shape[1]\n",
    "splt_width = int(np.ceil(np.sqrt(1.0*nb_chans+1)))  # adding an extra plot with all channels combined at the end\n",
    "fig, ax = plt.subplots(splt_width,splt_width)\n",
    "\n",
    "evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
    "               Target=list(epochs['Target'].iter_evoked()))\n",
    "#picks = [f'eeg{n}' for n in range(10, 15)]\n",
    "\n",
    "shape_epochs = epochs['Target']._data.shape\n",
    "for ch_idx in range(nb_chans):\n",
    "    print('plotting channel {}'.format(ch_idx+1))\n",
    "    mne.viz.plot_compare_evokeds(evokeds,picks=[epochs.info['ch_names'][ch_idx]],\n",
    "                                 legend=False,\n",
    "                                 axes=ax[ch_idx//splt_width, ch_idx%splt_width],)\n",
    "    plt.show(block=False)\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=.5)\n",
    "    plt.pause(.1)\n",
    "print('plotting averaged channels')\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=picks, combine='mean',\n",
    "                             legend=True,\n",
    "                             axes=ax[-1,-1])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>Target: 100<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.500 – 0.602 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.500 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  100 events (all good), -0.5 - 0.601562 sec, baseline -0.5 – 0 sec, ~1.7 MB, data loaded,\n",
       " 'Target': 100>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8, 283)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs['Target']._data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display single epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "combining channels using \"mean\"\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "600 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "combining channels using \"mean\"\n"
     ]
    }
   ],
   "source": [
    "epochs['Target'].plot_image(combine='mean')\n",
    "plt.gcf().canvas.set_window_title('Target')\n",
    "epochs['NonTarget'].plot_image(combine='mean')\n",
    "plt.gcf().canvas.set_window_title('Non-Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>11 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 8 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>256.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.50 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>40.00 Hz</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Info | 8 non-empty values\n",
       " bads: []\n",
       " ch_names: Fz, Cz, P3, Pz, P4, PO7, PO8, Oz\n",
       " chs: 8 EEG\n",
       " custom_ref_applied: False\n",
       " dig: 11 items (3 Cardinal, 8 EEG)\n",
       " highpass: 0.5 Hz\n",
       " lowpass: 40.0 Hz\n",
       " meas_date: unspecified\n",
       " nchan: 8\n",
       " projs: []\n",
       " sfreq: 256.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Layout | EEG - Channels: Fz, Cz, P3 ...>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.channels.find_layout(epochs.info, ch_type='eeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for trials that should be rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>NonTarget: 600<br>Target: 100<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.500 – 0.602 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.500 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  700 events (all good), -0.5 - 0.601562 sec, baseline -0.5 – 0 sec, ~12.1 MB, data loaded,\n",
       " 'NonTarget': 600\n",
       " 'Target': 100>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reject_criteria = dict(eeg=150e-6)       # 150 µV\n",
    "\n",
    "for ch_type, title in dict(eeg='EEG').items():\n",
    "    layout = mne.channels.find_layout(epochs.info, ch_type=ch_type)\n",
    "    epochs['Target'].plot_topo_image(layout=layout, fig_facecolor='w',\n",
    "                                            font_color='k', title=title+'Target Trial x time amplitude')\n",
    "    epochs['NonTarget'].plot_topo_image(layout=layout, fig_facecolor='w',\n",
    "                                            font_color='k', title=title+'Non-Target Trial x time amplitude')\n",
    "epochs.drop_bad(reject=reject_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference Target vs Non-Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diff_vis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-db9de5b98eeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnb_chans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiff_vis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msplt_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnb_chans\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# adding an extra plot with all channels combined at the end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplt_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplt_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
      "\u001b[1;31mNameError\u001b[0m: name 'diff_vis' is not defined"
     ]
    }
   ],
   "source": [
    "nb_chans = diff_vis._data.shape[1]\n",
    "splt_width = int(np.ceil(np.sqrt(1.0*nb_chans+1)))  # adding an extra plot with all channels combined at the end\n",
    "fig, ax = plt.subplots(splt_width,splt_width)\n",
    "\n",
    "evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
    "               Target=list(epochs['Target'].iter_evoked()))\n",
    "#picks = [f'eeg{n}' for n in range(10, 15)]\n",
    "\n",
    "shape_epochs = epochs['Target']._data.shape\n",
    "for ch_idx in range(nb_chans):\n",
    "    print('plotting channel {}'.format(ch_idx+1))\n",
    "    mne.viz.plot_compare_evokeds(evokeds,picks=[epochs.info['ch_names'][ch_idx]],\n",
    "                                 legend=False,\n",
    "                                 axes=ax[ch_idx//splt_width, ch_idx%splt_width],)\n",
    "    plt.show(block=False)\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=.5)\n",
    "    plt.pause(.1)\n",
    "print('plotting averaged channels')\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=picks, combine='mean',\n",
    "                             legend=True,\n",
    "                             axes=ax[-1,-1])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_balanced, _ = epochs.equalize_event_counts(event_ids=event_ids, method='truncate')\n",
    "epochs_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_nt_balanced = epochs_balanced['NonTarget'].average()\n",
    "l_target_balanced = epochs_balanced['Target'].average()\n",
    "diff_vis = mne.combine_evoked([l_target_balanced, l_nt_balanced], weights=[1, -1])\n",
    "diff_vis.plot_joint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand average (disabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Grand average of all signal (useless here, but would be good for averaging all participants or runs or clusters of runs)\n",
    "    grand_average = mne.grand_average([epochs['Target'].average(), epochs['NonTarget'].average()])\n",
    "    print(grand_average)\n",
    "    grand_average.evoked()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    #kwargs = dict(n_permutations=100, step_down_p=0.05, seed=1,\n",
    "    #              buffer_size=None, out_type='mask')\n",
    "    mne.stats.permutation_t_test()\n",
    "    \n",
    "\n",
    "    \n",
    "X = epochs._data[:,1,:]  # input data at CZ (TODO:flatten all electrodes)\n",
    "X = epochs._data[:,:,:]  # input data at CZ (TODO:flatten all electrodes)\n",
    "y = epochs.events[:,2]  # ground truth\n",
    "\n",
    "# remove the information \n",
    "    \n",
    "#mne.stats.permutation_t_test()\n",
    "#X.shape\n",
    "X = np.moveaxis(X,1,-1)\n",
    "X = X.reshape([X.shape[0],X.shape[1]*X.shape[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis(solver='lsqr',shrinkage='auto')\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9071428571428571\n",
      "0.9142857142857143\n",
      "0.9142857142857143\n",
      "0.95\n",
      "0.9142857142857143\n",
      "Average accuracy 5-Fold = 0.9200000000000002\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "transformed = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    kscore = clf.score(X_test,y_test)\n",
    "    print(kscore)\n",
    "    accuracy.append(kscore)\n",
    "    #transformed.append(clf.transform(X_test))\n",
    "print('Average accuracy {}-Fold = {}'.format(kf.get_n_splits(X), np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf_array = np.array(transformed)\n",
    "kf_array.shape\n",
    "#kf_array = kf_array.mean(axis=0)\n",
    "kf_array = kf_array.reshape(kf_array.size,1)\n",
    "kf_array.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LDA dataset')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_names = ['NonTarget', 'Target']\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "lw = 2\n",
    "\n",
    "plt.figure()\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(kf_array[y == i, 0], kf_array[y == i, 0], alpha=.8, color=color,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-a9cd8a611779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "X_r[y == i, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochs['NonTarget']._data.shape)\n",
    "m_nt = epochs['NonTarget']._data[:,1,...]\n",
    "m_t = epochs['Target']._data[:,1,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the r_squared calculation function adapted for handling MNE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/bbci/wyrm/blob/master/wyrm/processing.py\n",
    "# Bastian Venthur for wyrm\n",
    "# Code initially from Benjamin Blankertz for bbci (Matlab)\n",
    "\n",
    "def calculate_signed_r_square_mne(epochs, classes=[0,1], classaxis=0, **kwargs):\n",
    "    \"\"\"Calculate the signed r**2 values.\n",
    "    This method calculates the signed r**2 values over the epochs of the\n",
    "    ``dat``.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : MNE epoched data\n",
    "    classes: list, optional \n",
    "        (either int index or str for the class name of the epoch))\n",
    "    classaxis : int, optional\n",
    "        the dimension containing epochs\n",
    "    Returns\n",
    "    -------\n",
    "    signed_r_square : ndarray\n",
    "        the signed r**2 values, signed_r_square has one axis less than\n",
    "        the ``dat`` parameter, the ``classaxis`` has been removed\n",
    "    Examples\n",
    "    --------\n",
    "    >>> dat.data.shape\n",
    "    (400, 100, 64)\n",
    "    >>> r = calculate_signed_r_square(dat)\n",
    "    >>> r.shape\n",
    "    (100, 64)\n",
    "    \"\"\"\n",
    "    # TODO: explain the algorithm in the docstring and add a reference\n",
    "    # to a paper.\n",
    "    # select class 0 and 1\n",
    "    # TODO: make class 0, 1 variables\n",
    "    fv1 = epochs[classes[0]]._data\n",
    "    fv2 = epochs[classes[1]]._data\n",
    "    # number of epochs per class\n",
    "    l1 = epochs[classes[0]]._data.shape[classaxis]\n",
    "    l2 = epochs[classes[1]]._data.shape[classaxis]\n",
    "    # calculate r-value (Benjamin approved!)\n",
    "    a = (fv1.mean(axis=classaxis) - fv2.mean(axis=classaxis)) * np.sqrt(l1 * l2)\n",
    "    b = epochs._data.std(axis=classaxis) * (l1 + l2)\n",
    "    r = a / b\n",
    "    # return signed r**2\n",
    "    return np.sign(r) * np.square(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply signed r square function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display using \n",
    "rsq = calculate_signed_r_square_mne(epochs, classes=['Target','NonTarget'])\n",
    "#rsq.shape\n",
    "#plt.imshow(rsq, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "hm = sns.heatmap(rsq,linewidths=0,cmap=\"coolwarm\").set(title='Signed r-square maps Target vs Non-Target', xlabel='Time (samples)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "326.85px",
    "left": "914px",
    "right": "20px",
    "top": "391px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
