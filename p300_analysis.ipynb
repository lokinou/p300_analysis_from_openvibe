{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f07914",
   "metadata": {},
   "source": [
    "# P300 analysis from OpenVibe/BCI2000\n",
    "With lots of cool preprocessing features.\n",
    "source: [https://github.com/lokinou/p300_analysis_from_openvibe](https://github.com/lokinou/p300_analysis_from_openvibe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d777ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the line wit qt below to obtain separate plots\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d2b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if packages are missing, uncomment and execute here or in anaconda prompt with p300mne env\n",
    "#!pip install \"git+https://github.com/nbara/python-meegkit\"\n",
    "#!pip install statsmodels pyriemann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64932226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "import itertools\n",
    "import re\n",
    "from pathlib import Path\n",
    "# LDA\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866800c5",
   "metadata": {},
   "source": [
    "## Define the analysis variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffefc7d",
   "metadata": {},
   "source": [
    "if you don't know how to convert the .ov files, please check my [ov to gdf tutorial](https://github.com/lokinou/openvibe_to_gdf_tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb2827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the gdf files\n",
    "#data_dir=r\"C:\\BCI\\dev\\p300_analysis_from_openvibe\"\n",
    "data_dir=r\"./data_sample\"\n",
    "data_type= None  # bci2000 or openvibe or None for autodetection\n",
    "\n",
    "# Define the electrodes here (for the provided sample file)\n",
    "cname = None\n",
    "cname = ['Fz', 'FC1', 'FC2', 'C1', 'Cz', 'C2', 'P3', 'Pz', 'P4', 'Oz']\n",
    "#cname = ['Fz', 'Cz', 'P3', 'Pz', 'P4', 'PO7', 'PO8', 'Oz']\n",
    "\n",
    "# Visual\n",
    "skip_slow_ERP_plot = False  # skip the channelwise ERP plot\n",
    "display_preprocessing_plots = True\n",
    "display_all_erp_plots = True\n",
    "export_figures = True\n",
    "fig_folder = './out'\n",
    "\n",
    "# Preprocessing\n",
    "apply_resample = True # in case the sampling rate is high (>=256Hz)\n",
    "resample_freq = 256 # Hz\n",
    "apply_infinite_reference = False  # rereferencing\n",
    "apply_ASR = True  # use Artifact Subspace Reconstruction (artifact removal)\n",
    "apply_CSD = False  # use Current Source Density (spatial filter)\n",
    "\n",
    "drop_bad_epochs = False\n",
    "reject_channels_full_of_artifacts = True\n",
    "reject_artifactual_epochs = reject_channels_full_of_artifacts and True # do not reject epochs if you dont reject channels or use CSD\n",
    "artifact_threshold = 100e-6\n",
    "ratio_tolerated_artifacts = 0.3  # if 30% of artifacts in 200ms windows, then the channel is rejected\n",
    "\n",
    "# ERP analysis parameters (values in sec)\n",
    "pre_epoch = -.2\n",
    "epoch_length = .6\n",
    "baseline = (-.2, 0)\n",
    "#isi = .0625\n",
    "#flash = .125\n",
    "\n",
    "\n",
    "# LDA\n",
    "resample_LDA = 32 # Hz\n",
    "nb_k_splits = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041485e",
   "metadata": {},
   "source": [
    "## Load the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eda1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BCI2kReader import BCI2kReader as b2k\n",
    "from BCI2kReader import FileReader as f2k\n",
    "\n",
    "raws = []\n",
    "\n",
    "def extract_annotations(filename, verbose=False):\n",
    "    file = b2k.BCI2kReader(filename)\n",
    "    if verbose:\n",
    "        print(file.states)\n",
    "    target_states = np.squeeze(file.states['StimulusType'])\n",
    "    stimulus_states = np.squeeze(file.states['StimulusCode'])\n",
    "    if 'StimulusBegin' in file.states.keys():\n",
    "        stimulus_begin = np.squeeze(file.states['StimulusBegin'])\n",
    "    else:\n",
    "        stimulus_begin = np.squeeze(file.states['Flashing'])\n",
    "    fs = file.samplingrate\n",
    "    idx_targets = np.where(target_states)[0]\n",
    "    idx_codes = np.where(stimulus_states>0)[0]\n",
    "    idx_begin = np.where(stimulus_begin>0)[0]\n",
    "\n",
    "\n",
    "    # In BCI2000 states are maintained over different samples, we search here the differences of when the codes are > 0\n",
    "    groups = np.split(idx_codes, np.where(np.diff(idx_codes) != 1)[0]+1)\n",
    "    # we take the first sample where a difference can be found\n",
    "    code_change_idx = np.array([g[0] for g in groups])\n",
    "    #[idx_codes[idx] for idx in code_change_idx]\n",
    "    print('nb stimuli={}'.format(len(code_change_idx)))\n",
    "\n",
    "    # we intersect the target index list with the code change to find the onset of targets and non-targets\n",
    "    target_idx=np.intersect1d(code_change_idx,idx_targets)\n",
    "    print('nb targets={}'.format(len(target_idx)))\n",
    "    non_target_idx= np.setdiff1d(code_change_idx,idx_targets)\n",
    "\n",
    "    # Translating into MNE Annotations \n",
    "    # define the annotations from the recovered stimuli (in seconds)\n",
    "    sample_lengh = 1/fs\n",
    "    onsets = code_change_idx * sample_lengh\n",
    "    # define the descriptio\n",
    "    description = np.zeros(code_change_idx.shape, dtype=np.uint)\n",
    "    # index of targets in the list of stimuli onsets\n",
    "    description[np.searchsorted(code_change_idx, target_idx)] = 1\n",
    "    if display_preprocessing_plots:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(description[:100])\n",
    "        fig.suptitle('Targets(1) and non-targets(0) for 100 first stimuli')\n",
    "\n",
    "    # set minimum duration (should not matter)\n",
    "    duration = np.ones(code_change_idx.shape) * sample_lengh\n",
    "    file.flush()\n",
    "\n",
    "    return mne.Annotations(onset=onsets, duration=duration, description=description)\n",
    "\n",
    "def load_bci2k(filename_list):\n",
    "    raws = []\n",
    "    for fn in filename_list:\n",
    "        cname = None\n",
    "        with b2k.BCI2kReader(fn) as file:\n",
    "            \n",
    "            # Extract signals and states\n",
    "            print('opened')\n",
    "            eeg_data = file.signals\n",
    "            states = file.states\n",
    "            fs = file.samplingrate\n",
    "            nb_chan = eeg_data.shape[0]\n",
    "            #file.purge()\n",
    "\n",
    "            # Extract channel names\n",
    "            reader = f2k.bcistream(fn)\n",
    "            # actualize the parameters by including the defined channel names\n",
    "            if len(reader.params['ChannelNames']):\n",
    "                if cname != reader.params['ChannelNames']:\n",
    "                    cname = reader.params['ChannelNames']\n",
    "                    print('Actualized channel names to {}'.format(cname))\n",
    "\n",
    "            if cname is None:\n",
    "                cname = [str(ch_n) for ch_n in list(range(nb_chan))]\n",
    "                \n",
    "            # convert states into annotations\n",
    "            info = mne.create_info(cname, fs, ch_types='eeg', verbose=None)\n",
    "            raw_array = mne.io.RawArray(eeg_data, info)\n",
    "            # Manually force the filename or mne complains\n",
    "            raw_array._filenames = [os.path.basename(fn)]\n",
    "            \n",
    "            annotations = extract_annotations(fn)\n",
    "            raw_array.set_annotations(annotations)\n",
    "            raws.append(raw_array)\n",
    "    return raws\n",
    "\n",
    "#fn = [\"./data_sample/bci2000\\Heide_einsteinBP_calibration4S001R01.dat\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a34fae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_sample\\bp2calib.dat\n",
      "opened\n",
      "Creating RawArray with float64 data, n_channels=10, n_times=57824\n",
      "    Range : 0 ... 57823 =      0.000 ...   225.871 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb stimuli=1050\n",
      "nb targets=150\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.path.exists(data_dir)\n",
    "fnames = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".gdf\"):\n",
    "        data_type = 'openvibe'\n",
    "        fnames.append(os.path.join(data_dir, file))\n",
    "        print(os.path.join(data_dir, file))\n",
    "    elif file.endswith(\".dat\"):\n",
    "        data_type = 'bci2000'\n",
    "        print(os.path.join(data_dir, file))\n",
    "        fnames.append(os.path.join(data_dir, file))\n",
    "        \n",
    "if data_type == 'openvibe':\n",
    "    # load and preprocess data ####################################################\n",
    "    raws = [mne.io.read_raw_gdf(f, preload=True) for f in fnames]\n",
    "elif data_type == 'bci2000':\n",
    "    raws = load_bci2k(fnames)\n",
    "raw = mne.concatenate_raws(raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29780a12-ad87-46f7-b00a-8992734229e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ebeb81d-d08c-4a59-a013-fe1ecb6dda0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb stimuli=1050\n",
      "nb targets=150\n"
     ]
    }
   ],
   "source": [
    "verbose=False\n",
    "display_preprocessing_plots = False\n",
    "file= b2k.BCI2kReader(os.path.abspath('./data_sample/bp2calib.dat'))\n",
    "\n",
    "if verbose:\n",
    "    print(file.states)\n",
    "target_states = np.squeeze(file.states['StimulusType'])\n",
    "stimulus_codes = np.squeeze(file.states['StimulusCode'])\n",
    "if 'StimulusBegin' in file.states.keys():\n",
    "    stimulus_begin = np.squeeze(file.states['StimulusBegin'])\n",
    "else:\n",
    "    stimulus_begin = np.squeeze(file.states['Flashing'])\n",
    "\n",
    "phase = np.squeeze(file.states['PhaseInSequence'])\n",
    "    \n",
    "fs = file.samplingrate\n",
    "\n",
    "idx_targets = np.where(target_states)[0]\n",
    "idx_codes = np.where(stimulus_codes>0)[0]\n",
    "idx_begin = np.where(stimulus_begin>0)[0]\n",
    "\n",
    "\n",
    "# In BCI2000 states are maintained over different samples, we search here the differences of when the codes are > 0\n",
    "groups = np.split(idx_codes, np.where(np.diff(idx_codes) != 1)[0]+1)\n",
    "# we take the first sample where a difference can be found\n",
    "code_change_idx = np.array([g[0] for g in groups])\n",
    "#[idx_codes[idx] for idx in code_change_idx]\n",
    "print('nb stimuli={}'.format(len(code_change_idx)))\n",
    "\n",
    "# we intersect the target index list with the code change to find the onset of targets and non-targets\n",
    "target_idx=np.intersect1d(code_change_idx,idx_targets)\n",
    "print('nb targets={}'.format(len(target_idx)))\n",
    "non_target_idx= np.setdiff1d(code_change_idx,idx_targets)\n",
    "\n",
    "# Translating into MNE Annotations \n",
    "# define the annotations from the recovered stimuli (in seconds)\n",
    "sample_lengh = 1/fs\n",
    "onsets = code_change_idx * sample_lengh\n",
    "# define the descriptio\n",
    "description = np.zeros(code_change_idx.shape, dtype=np.uint)\n",
    "# index of targets in the list of stimuli onsets\n",
    "description[np.searchsorted(code_change_idx, target_idx)] = 1\n",
    "if display_preprocessing_plots:\n",
    "    fig = plt.figure()\n",
    "    plt.plot(description[:100])\n",
    "    fig.suptitle('Targets(1) and non-targets(0) for 100 first stimuli')\n",
    "    \n",
    "if display_preprocessing_plots:\n",
    "    fig = plt.figure()\n",
    "    plt.plot(phase == 1)\n",
    "    fig.suptitle('Trial begin')\n",
    "\n",
    "# extract trial begin markers\n",
    "new_phase_continuous = np.where(phase == 1)[0]\n",
    "groups = np.split(new_phase_continuous, np.where(np.diff(new_phase_continuous) != 1)[0]+1)\n",
    "new_trial_idx = np.array([g[0] for g in groups])\n",
    "new_trial_idx\n",
    "\n",
    "# extract trials duration\n",
    "inter_trial_duration = [new_trial_idx[n+1]-new_trial_idx[n] for n in list(range(len(new_trial_idx)-1))]\n",
    "print(\"Extracted {} trials\".format(len(new_trial_idx)))\n",
    "# Check whether the time between trials is identical or it could cause overlap\n",
    "\n",
    "# set minimum duration (should not matter)\n",
    "duration = np.ones(code_change_idx.shape) * sample_lengh\n",
    "file.flush()\n",
    "\n",
    "an = mne.Annotations(onset=onsets, duration=duration, description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "053f9a3b-9862-47d9-9eb4-f3e618e76379",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-fe012c18cb22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrial_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0minter_trial_duration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extracted {} trials\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-fe012c18cb22>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrial_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0minter_trial_duration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extracted {} trials\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_trial_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58513759-e223-4bd4-8f6d-9da09a7b1e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Running': array([[1, 1, 1, ..., 1, 1, 1]]),\n",
       " 'Recording': array([[1, 1, 1, ..., 1, 1, 1]]),\n",
       " 'SourceTime': array([[40196, 40196, 40196, ...,  3861,  3861,  3861]]),\n",
       " 'StimulusCode': array([[0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'StimulusType': array([[0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'StimulusBegin': array([[0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'PhaseInSequence': array([[0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'PauseApplication': array([[0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'SelectedTarget': array([[0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'SelectedRow': array([[0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'SelectedColumn': array([[0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'SpellerMenu': array([[0, 0, 0, ..., 1, 1, 1]]),\n",
       " 'StimulusTime': array([[   0,    0,    0, ..., 3800, 3800, 3800]]),\n",
       " 'StimulusCodeRes': array([[0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'StimulusTypeRes': array([[0, 0, 0, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471aa253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaled signal to Volt (mean variance=2.749515417312947e-10)\n"
     ]
    }
   ],
   "source": [
    "# If the variance of the data is >1, it means the data is expressed in microvolts\n",
    "# Since MNE uses Volt as a default value, we rescale microvolts to volt\n",
    "if np.var(raw._data)>1:\n",
    "    raw._data = raw._data * 1.e-6\n",
    "    print('Rescaled signal to Volt (mean variance={})'.format(np.var(raw._data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518983d",
   "metadata": {},
   "source": [
    "Create a name for figures output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = Path(raw._filenames[0]).stem\n",
    "if len(raw._filenames)>1:\n",
    "    output_name = output_name + '_{}_files'.format(len(raw._filenames))\n",
    "print('Figures will have the name: {}'.format(output_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4461997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_preprocessing_plots:\n",
    "    raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97b8f2",
   "metadata": {},
   "source": [
    "## Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b534c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_resample:\n",
    "    raw.resample(resample_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60242a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "\n",
    "if cname is None:\n",
    "    cname = raw.info['ch_names']\n",
    "    print('Using channel names directly from the data files: {}'.format(cname))\n",
    "else:\n",
    "    print('Using user defined channel names: {}'.format(cname))\n",
    "        \n",
    "\n",
    "nb_chan = len(raw.info['ch_names'])\n",
    "nb_def_ch = len(cname)\n",
    "\n",
    "# regular expressions to look for certain channel types\n",
    "eog_pattern = re.compile('eog|EOG')  # EOG electrodes\n",
    "emg_pattern = re.compile('emg|EMG')  # EMG electrodes\n",
    "mastoid_pattern = re.compile('^[aA][0-9]+')  # A1 and A2 electrodes (mastoids)\n",
    "\n",
    "\n",
    "types = []\n",
    "cname_map = dict(zip(raw.info['ch_names'], cname))\n",
    "for nc in cname:\n",
    "    if eog_pattern.search(nc) is not None:\n",
    "        t = 'eog'\n",
    "    elif emg_pattern.search(nc) is not None:\n",
    "        t = 'emg'\n",
    "    elif mastoid_pattern.search(nc) is not None:\n",
    "        t = 'misc'\n",
    "    elif nc in montage.ch_names:  # check the 10-05 montage for all electrode names\n",
    "        t = 'eeg'\n",
    "    else:\n",
    "        t = 'misc'  # if not found, discard the channel as misc\n",
    "    \n",
    "    types.append(t)\n",
    "        \n",
    "type_map = dict(zip(cname, types))\n",
    "\n",
    "# rename and pick eeg\n",
    "raw.rename_channels(cname_map, allow_duplicates=False)\n",
    "raw.set_channel_types(type_map)\n",
    "raw.pick_types(eeg=True, misc=False)\n",
    "print('Electrode mapping')\n",
    "type_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8475591f",
   "metadata": {},
   "source": [
    "rename the electrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bdc3cc",
   "metadata": {},
   "source": [
    "Set the montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46773eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.set_montage(montage, match_case=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1199c75a",
   "metadata": {},
   "source": [
    "Check whether there are bad channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef84aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 50Hz power variance\n",
    "psd, freqs = mne.time_frequency.psd_welch(raw,verbose=True)\n",
    "power_50hz = psd[:,np.where(freqs ==60)]\n",
    "print('50Hz variance: {}'.format(mne.preprocessing.bads._find_outliers(power_50hz.squeeze(), threshold=3, max_iter=5, tail=0)))\n",
    "\n",
    "\n",
    "# using variance\n",
    "ch_var  = [np.var(raw._data[i,:]) for i in list(range(raw._data.shape[0]))]\n",
    "print('Variance: {}'.format(mne.preprocessing.bads._find_outliers(ch_var, threshold=3, max_iter=5, tail=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e9f7e",
   "metadata": {},
   "source": [
    "rereferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_infinite_reference:\n",
    "    raw.del_proj()  # remove our average reference projector first\n",
    "    sphere = mne.make_sphere_model('auto', 'auto', raw.info)\n",
    "    src = mne.setup_volume_source_space(sphere=sphere, exclude=30., pos=15.)\n",
    "    forward = mne.make_forward_solution(raw.info, trans=None, src=src, bem=sphere)\n",
    "    raw_rest = raw.copy().set_eeg_reference('REST', forward=forward)\n",
    "    \n",
    "    if display_preprocessing_plots:\n",
    "        for title, _raw in zip(['Original', 'REST (∞)'], [raw, raw_rest]):\n",
    "            fig = _raw.plot(n_channels=len(raw), scalings=dict(eeg=5e-5))\n",
    "            # make room for title\n",
    "            fig.subplots_adjust(top=0.9)\n",
    "            fig.suptitle('{} reference'.format(title), size='xx-large', weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ce84f",
   "metadata": {},
   "source": [
    "## Bandpass the signal\n",
    "Removes noise and drift from the EEG signal by applying a infinite impulse response (two-pass) filter between .5 and 40Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.filter(.5, 40, fir_window='hann', method='iir')\n",
    "raw.notch_filter(50)  # removes 50Hz noise\n",
    "if display_preprocessing_plots:\n",
    "    raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4224b322",
   "metadata": {},
   "source": [
    "## Excluding of channels full of artifacts (muscular or disconnecting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Apply a variance based channel rejection if artifacts are present >30% of the time\n",
    "def detec_rej_channel(raw, duration=.2, overlap_duration=.1, threshold_eeg=artifact_threshold, reject_ratio=ratio_tolerated_artifacts):\n",
    "\n",
    "    epochs_rej = mne.make_fixed_length_epochs(raw,duration=duration, overlap=overlap_duration, preload=True)\n",
    "    epochs_rej._data.shape\n",
    "    diff = np.max(epochs_rej._data, axis=2) - np.min(epochs_rej._data, axis=2)\n",
    "\n",
    "    print(diff.shape)\n",
    "\n",
    "    rej = (diff>=threshold_eeg).astype(np.float64)\n",
    "    rel = sns.heatmap(rej)\n",
    "    rel.set(title='Detected artifacts per electrode and runs (white)')\n",
    "\n",
    "    # calculate ratio of rejected trials\n",
    "    ratios = np.sum(rej,axis=0) / rej.shape[0]\n",
    "    \n",
    "    ret = np.argwhere(ratios >= reject_ratio).tolist()\n",
    "    if len(ret)>0 and len(ret[0]):\n",
    "        print('Found {} channels with at least {}% {}s epochs > {} amplitude)'.format(len(ret), \n",
    "                                                                                              reject_ratio*100, duration,\n",
    "                                                                                      threshold_eeg))\n",
    "        return ret[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "if reject_channels_full_of_artifacts:\n",
    "    rej_ch = detec_rej_channel(raw)\n",
    "    if rej_ch is not None:\n",
    "        new_bads = [raw.info['ch_names'][ch] for ch in rej_ch]\n",
    "        raw.info['bads'].extend(new_bads)\n",
    "        raw.pick_types(eeg=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4563dccf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Artifact Subspace Reconstruction fitting and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_ASR:\n",
    "    #!pip install meegkit pymanopt\n",
    "    from meegkit.asr import ASR\n",
    "    fs = int(raw.info[\"sfreq\"])  # sampling frequency\n",
    "    method='riemann'  # if error, use 'euclid'\n",
    "    method='euclid' # pymanopt library still buggy\n",
    "    window_s=.5  # .5 sec window of analysis\n",
    "    data_interval_s  = None # (begin, end) in sec of the training sample\n",
    "    estimator='lwf'  #leave blank if using euclidian mode \n",
    "\n",
    "    # define the ASR model using riemannian method\n",
    "    #asr_model = ASR(sfreq=fs, method=method, win_len=window_s, estimator=estimator)\n",
    "\n",
    "    # if failing (after trying twice. SVD error occurs for no reason sometimes)\n",
    "    asr_model = ASR(sfreq=fs, method=method, win_len=window_s)\n",
    "\n",
    "    # The best would be to choose another recording during the same session to train the model without overfitting\n",
    "    data = raw._data  # the numpy array with data is stored in the _data variable\n",
    "\n",
    "    # Select a time interval for training data\n",
    "    train_idx = None\n",
    "    if data_interval_s is not None:\n",
    "        train_idx = np.arange(data_interval_s[0] * fs, data_interval_s[1] * fs, dtype=int)\n",
    "    # otherwise select the whole training set\n",
    "    else:\n",
    "        train_idx = np.arange(0, data.shape[1])\n",
    "\n",
    "    train_data = data[:, train_idx]\n",
    "    print('Training on samples of size {}'.format(train_data.shape))\n",
    "\n",
    "    # fir the ASR model with data intervals\n",
    "    _, sample_mask = asr_model.fit(train_data)\n",
    "    print('Model trained')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62943a",
   "metadata": {},
   "source": [
    "### Clean the current dataset\n",
    "Please check whether using this artifact filtering method increases signal to noise ratio rather than reducing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_ASR:\n",
    "    clean =  asr_model.transform(raw._data)\n",
    "\n",
    "    display_window_s = 60  # \n",
    "\n",
    "    if display_preprocessing_plots:  #\n",
    "        data_p = raw._data[0:fs*display_window_s]  # reshape to (n_chans, n_times)\n",
    "        clean_p = clean[0:fs*display_window_s]\n",
    "\n",
    "        ###############################################################################\n",
    "        # Plot the results\n",
    "        # -----------------------------------------------------------------------------\n",
    "        #\n",
    "        # Data was trained on a 40s window from 5s to 45s onwards (gray filled area).\n",
    "        # The algorithm then removes portions of this data with high amplitude\n",
    "        # artifacts before running the calibration (hatched area = good).\n",
    "        nb_ch_disp = len(raw.info['ch_names'])\n",
    "        times = np.arange(data_p.shape[-1]) / fs\n",
    "        f, ax = plt.subplots(nb_ch_disp, sharex=True, figsize=(32, 16))\n",
    "        for i in range(nb_ch_disp):\n",
    "            # ax[i].fill_between(train_idx / fs, 0, 1, color='grey', alpha=.3,\n",
    "            #                   transform=ax[i].get_xaxis_transform(),\n",
    "            #                   label='calibration window')\n",
    "            # ax[i].fill_between(train_idx / fs, 0, 1, where=sample_mask.flat,\n",
    "            #                   transform=ax[i].get_xaxis_transform(),\n",
    "            #                   facecolor='none', hatch='...', edgecolor='k',\n",
    "            #                   label='selected window')\n",
    "            ax[i].plot(times, data_p[i], lw=.5, label='before ASR')\n",
    "            ax[i].plot(times, clean_p[i], label='after ASR', lw=.5)\n",
    "            # ax[i].plot(times, raw[i]-clean[i], label='Diff', lw=.5)\n",
    "            # ax[i].set_ylim([-50, 50])\n",
    "            ax[i].set_ylabel(f'ch{i}')\n",
    "            ax[i].set_yticks([])\n",
    "        ax[i].set_xlabel('Time (s)')\n",
    "        ax[0].legend(fontsize='small', bbox_to_anchor=(1.04, 1), borderaxespad=0)\n",
    "        plt.subplots_adjust(hspace=0, right=0.75)\n",
    "        plt.suptitle('Before/after ASR')\n",
    "        plt.show()\n",
    "    raw.data_ = clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a02ab2",
   "metadata": {},
   "source": [
    "### Convert text annotations (i.e. unprocessed events) into events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e61c1cd",
   "metadata": {},
   "source": [
    "**Small but major hack to realign events due to conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type=='openvibe':\n",
    "    print(\"Erroneous annotations: {}\".format(raw.annotations.description))\n",
    "    print('Note here that the first annotation is 0 or 1, this is an error and thus we shift the annotations to retrieve the correct timings')\n",
    "    raw.annotations.description = np.roll(raw.annotations.description, -1)\n",
    "    print(\"Corrected annotations: {}\".format(raw.annotations.description))\n",
    "\n",
    "    # in case you want to debug the issue, I left here a way to visualize them\n",
    "    # retrieving the list of annotations\n",
    "    import pprint\n",
    "    print(raw.annotations.to_data_frame())\n",
    "    df = raw.annotations.to_data_frame()\n",
    "    print('Displaying all annotations')\n",
    "    annot_codes = [np.int64(n) for n in np.unique(df['description'])]\n",
    "    df['description'] = df['description'].astype(int)\n",
    "\n",
    "    if False:\n",
    "        # to see and debug the fill list of annotations\n",
    "        import pandas as pd\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        #a = df[df['description'] != 33286]\n",
    "        #print(a)\n",
    "        print(df)\n",
    "        pd.set_option('display.max_rows', 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd225eb",
   "metadata": {},
   "source": [
    "### Make a list of the annotations to check whether all stimuli can be found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f06080",
   "metadata": {
    "tags": []
   },
   "source": [
    "These annotations seem to relate to hex codes. OpenViBE definitions can be found on [OpenViBE's website](http://openvibe.inria.fr/stimulation-codes/). Let's parse the copypasted list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc165b",
   "metadata": {},
   "source": [
    "Make a dataframe of the stimuli in common between both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d00367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "if data_type=='openvibe':\n",
    "    tr_sim= ''\n",
    "    pat_extract= re.compile('^([^ ]+)[ ]+0x[0-9A-Fa-f]+[ \\/]+([0-9]+)')\n",
    "    #OVTK_GDF_125_Watt                                     0x585       //  1413\n",
    "    k_stim = []\n",
    "    k_stim_int = []\n",
    "    v_stim = []\n",
    "\n",
    "    # read and convert annotations\n",
    "    with open(r'.\\ov_stims.txt', 'r') as fd:\n",
    "        for line in fd.readlines():\n",
    "            m = pat_extract.match(line)\n",
    "            v, k = m.groups()\n",
    "            k_stim.append(k)\n",
    "            k_stim_int.append(int(k))\n",
    "            v_stim.append(v)\n",
    "\n",
    "    # format dict and list\n",
    "    stim_map = dict(zip(k_stim_int, v_stim))\n",
    "    stim_map_inv = dict(zip(v_stim, k_stim))\n",
    "\n",
    "    stim_tup = list(zip(k_stim_int, v_stim))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(stim_tup)\n",
    "    df.columns = ['coden', 'desc']\n",
    "    df[[c in annot_codes for c in df.coden]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bfa34d",
   "metadata": {},
   "source": [
    "From this table, we could locate and save the codes for **Target and Non-Target** and give them the following values: target=1 and non-target=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686637bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = 1, nontarget = 0\n",
    "target_map = None\n",
    "if data_type == 'openvibe':\n",
    "    target_map = {'33286':0, '33285':1}\n",
    "elif data_type == \"bci2000\":\n",
    "    target_map = {'0':0, '1':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38d6e4e",
   "metadata": {},
   "source": [
    "Then we can convert annotations into events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24830d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, _ = mne.events_from_annotations(raw, event_id=target_map)\n",
    "print(\"Found {} events\".format(len(events[:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1347e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024a2da",
   "metadata": {},
   "source": [
    "### Pick the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick all channels\n",
    "picks = mne.pick_channels(raw.info[\"ch_names\"], include=[])\n",
    "picks\n",
    "raw.plot_sensors(show_names=True)\n",
    "fig = raw.plot_sensors('3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc1d00",
   "metadata": {},
   "source": [
    "## Epoching from events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac65f7ee",
   "metadata": {},
   "source": [
    "Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "events[:, 0]\n",
    "a = np.array(events[:, 0])\n",
    "dups = [item for item, count in Counter(a).items() if count > 1]\n",
    "if dups:\n",
    "    print(\"WARNING: Duplicate found at sample(s) {}\".format(dups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beabe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_ids = dict(NonTarget=0, Target=1) \n",
    "#isi = isi\n",
    "#flash = flash\n",
    "pre_epoch = pre_epoch\n",
    "epoch_length = epoch_length\n",
    "\n",
    "\n",
    "# epoching function\n",
    "epochs = mne.Epochs(raw, events, baseline=baseline, event_id=event_ids, tmin=pre_epoch, tmax=epoch_length, event_repeated='drop', picks = ['eeg', 'csd'],\n",
    "                    preload=True)\n",
    "\n",
    "# if there is any delay,\n",
    "#epochs.shift_time(-isi, relative=True)\n",
    "if display_preprocessing_plots:\n",
    "    fig = epochs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a91f1a",
   "metadata": {},
   "source": [
    "### Making a cross correlation plot between the electrodes to see how channels relate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ff9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.corrcoef(raw._data)\n",
    "fig = plt.figure()\n",
    "hm = sns.heatmap(m,linewidths=0,cmap=\"YlGnBu\").set(title='Cross correlation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced88097",
   "metadata": {},
   "source": [
    "### Epoch rejection\n",
    "Please filter out channels before epochs. A problematic channel can discard the whole recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c142c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if reject_artifactual_epochs:\n",
    "    reject_criteria = dict(eeg=150e-6)  # 100 µV  #eog=200e-6)\n",
    "    _ = epochs.drop_bad(reject=reject_criteria)\n",
    "    if display_preprocessing_plots:\n",
    "        epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30c19a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Apply current source density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3abf42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if apply_CSD:\n",
    "    epochs_csd = mne.preprocessing.compute_current_source_density(epochs)\n",
    "    epochs = epochs_csd\n",
    "    if display_preprocessing_plots:\n",
    "        epochs_csd.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd46a29b",
   "metadata": {},
   "source": [
    "### Average the epochs of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_nt = epochs['NonTarget'].average()\n",
    "l_target = epochs['Target'].average()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6729d3",
   "metadata": {},
   "source": [
    "target and non target signal plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_all_erp_plots:\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    fig1 = l_target.plot(spatial_colors=True, axes=ax[0], show=False)\n",
    "    fig2 = l_nt.plot(spatial_colors=True, axes=ax[1], show=False)\n",
    "    # Add title\n",
    "    fig.suptitle(\"Target(top) - Non-Target(bottom)\")\n",
    "    # Fix font spacing\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57d133",
   "metadata": {},
   "source": [
    "target and non target signal topomaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf7661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if display_all_erp_plots:\n",
    "    spec_kw = dict(width_ratios=[1,1,1,.15], wspace=0.5,\n",
    "                   hspace=0.5,height_ratios=[1,1])\n",
    "                             #hspace=0.5, height_ratios=[1, 2])\n",
    "\n",
    "    fig, ax = plt.subplots(2, 4, gridspec_kw=spec_kw)\n",
    "    l_target.plot_topomap(times=[0, 0.18, 0.4], average=0.05, axes=ax[0,:], show=False)\n",
    "    l_nt.plot_topomap(times=[0, 0.18, 0.4], average=0.05, axes=ax[1,:], show=False)\n",
    "    fig.suptitle(\"Target(top) - Non-Target(bottom)\")\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a88e9",
   "metadata": {},
   "source": [
    "joint plot (of the two former graphs). Plase not that Y scales differ between plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05494451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_target.plot_joint()\n",
    "plt.gcf().canvas.set_window_title('Target joint plot')\n",
    "l_nt.plot_joint()\n",
    "plt.gcf().canvas.set_window_title('Non-Target joint plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac1c6bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Average plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f086da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if display_all_erp_plots:\n",
    "    evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
    "                   Target=list(epochs['Target'].iter_evoked()))\n",
    "    #picks = [f'eeg{n}' for n in range(10, 15)]\n",
    "    mne.viz.plot_compare_evokeds(evokeds, picks=picks, combine='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fb9b1",
   "metadata": {},
   "source": [
    "### Target vs NonTarget Erps per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ddccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_slow_ERP_plot:\n",
    "    nb_chans = epochs['Target']._data.shape[1]\n",
    "    splt_width = int(np.floor(np.sqrt(1.0*nb_chans+1)))  # adding an extra plot with all channels combined at the end\n",
    "    splt_height = splt_width if splt_width * splt_width >= nb_chans+1 else splt_width+1\n",
    "    if splt_height * splt_width < nb_chans+1:\n",
    "        splt_height += 1\n",
    "    fig, ax = plt.subplots(splt_height,splt_width)\n",
    "\n",
    "    evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
    "                   Target=list(epochs['Target'].iter_evoked()))\n",
    "    #picks = [f'eeg{n}' for n in range(10, 15)]\n",
    "\n",
    "    shape_epochs = epochs['Target']._data.shape\n",
    "    for ch_idx in range(nb_chans):\n",
    "        print('plotting channel {}'.format(ch_idx+1))\n",
    "        mne.viz.plot_compare_evokeds(evokeds,picks=[epochs.info['ch_names'][ch_idx]],\n",
    "                                     legend=False,\n",
    "                                     axes=ax[ch_idx//splt_width, ch_idx%splt_width], show=False)\n",
    "        #plt.show(block=False)\n",
    "        plt.subplots_adjust(hspace=0.5, wspace=.5)\n",
    "        #plt.pause(.1)\n",
    "    print('plotting averaged channels')\n",
    "    axs = mne.viz.plot_compare_evokeds(evokeds, picks=picks, combine='mean',\n",
    "                                 legend=True,\n",
    "                                 axes=ax[-1,-1], show=False)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=.5)\n",
    "    plt.show()\n",
    "    print(\"Please note that this plot is optimized for higher resolution and has the legend overlapping the average\")\n",
    "\n",
    "    if export_figures:\n",
    "        out_name = os.path.join(fig_folder, output_name + '_ERPs')\n",
    "        axs[0].savefig(out_name, dpi=300, facecolor='w', edgecolor='w', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7930da8",
   "metadata": {},
   "source": [
    "### Display epoch at Cz and Pz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fdec8",
   "metadata": {},
   "source": [
    "### Display single epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd310e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_all_erp_plots:\n",
    "    epochs['Target'].plot_image(combine='mean')\n",
    "    plt.gcf().canvas.set_window_title('Target')\n",
    "    epochs['NonTarget'].plot_image(combine='mean')\n",
    "    plt.gcf().canvas.set_window_title('Non-Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c0e3b",
   "metadata": {},
   "source": [
    "### Same plot but channel wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_slow_ERP_plot:\n",
    "    dict_electrodes = dict(eeg='EEG') if not apply_CSD else dict(csd='CSD')\n",
    "    if display_all_erp_plots:\n",
    "        for ch_type, title in dict_electrodes.items():\n",
    "            layout = mne.channels.find_layout(epochs.info, ch_type=ch_type)\n",
    "            epochs['Target'].plot_topo_image(layout=layout, fig_facecolor='w',\n",
    "                                                    font_color='k', title=title+' Target Trial x time amplitude')\n",
    "            epochs['NonTarget'].plot_topo_image(layout=layout, fig_facecolor='w',\n",
    "                                                    font_color='k', title=title+' Non-Target Trial x time amplitude')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f4d9f1",
   "metadata": {},
   "source": [
    "# Assess ERP classificaiton accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5057efa",
   "metadata": {},
   "source": [
    "resample the signal, we don't need that much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a299028",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fs = resample_LDA #\n",
    "epochs_resampled = epochs.copy().resample(new_fs)\n",
    "print('resampling to {}Hz'.format(new_fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2f656",
   "metadata": {},
   "source": [
    "modify the data matrix to be properly assessed via LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X = epochs_resampled._data[:,1,:]  # input data at CZ (TODO:flatten all electrodes)\n",
    "X = epochs_resampled._data[:,:,:]  # input data at CZ (TODO:flatten all electrodes)\n",
    "y = epochs_resampled.events[:,2]  # ground truth\n",
    "\n",
    "# remove the information \n",
    "    \n",
    "#mne.stats.permutation_t_test()\n",
    "print('Data shape from MNE {}'.format(X.shape))\n",
    "X = np.moveaxis(X,1,-1)\n",
    "print('new data shape with sampling prioritized over channels {}'.format(X.shape))\n",
    "X = X.reshape([X.shape[0],X.shape[1]*X.shape[2]],order='C')\n",
    "print('Shape for K-fold LDA {}'.format(X.shape))\n",
    "\n",
    "# Think about splitting training sample and test samples\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d2a1d",
   "metadata": {},
   "source": [
    "### Compute k-fold LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a4f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearDiscriminantAnalysis(solver='lsqr',shrinkage='auto')\n",
    "kf = KFold(n_splits=nb_k_splits)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "list_score = []\n",
    "list_auc = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_kf, X_test_kf = X[train_index], X[test_index]\n",
    "    y_train_kf, y_test_kf = y[train_index], y[test_index]\n",
    "    clf.fit(X_train_kf, y_train_kf)\n",
    "    kscore = clf.score(X_test_kf,y_test_kf)\n",
    "    y_pred_kf = clf.predict(X_test_kf)\n",
    "    k_auc = roc_auc_score(y_test_kf, y_pred_kf)\n",
    "    print('fold score: {}, AUC={}'.format(np.round(kscore, decimals=3), np.round(k_auc, decimals=3)))\n",
    "    list_score.append(kscore)\n",
    "    list_auc.append(k_auc)\n",
    "    \n",
    "print('Average score {}-Fold = {}, AUC={}'.format(kf.get_n_splits(X), np.round(np.mean(list_score), decimals=2), np.round(np.mean(list_auc), decimals=2)))\n",
    "\n",
    "# using the training/validate samples, \n",
    "clf.fit(X_train, y_train)\n",
    "score  = clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print('Score training-validation {}, AUC={}'.format(np.round(score , decimals=2), np.round(auc, decimals=2)))\n",
    "\n",
    "print('Score is only valid if classes are balanced, please check AUC instead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_targets = epochs_resampled['Target'].events.shape[0]\n",
    "nb_non_targets = epochs_resampled['NonTarget'].events.shape[0]\n",
    "\n",
    "print('Data contains {}% of Non-targets'.format(np.round(100*(nb_non_targets / (epochs_resampled.events.shape[0])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fad580",
   "metadata": {},
   "source": [
    "### Display train-test LDA classification in a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conf_matrix(y,pred):\n",
    "    cmat = metrics.confusion_matrix(y, pred)\n",
    "    cmat_norm = metrics.confusion_matrix(y, pred, \n",
    "            normalize='true')\n",
    "    ((tn, fp), (fn, tp)) = cmat\n",
    "    ((tnr,fpr),(fnr,tpr)) = cmat_norm\n",
    "    \n",
    "    plt.figure()\n",
    "    labels = ['Non-Target', 'Target']\n",
    "    sns.heatmap(cmat, xticklabels=labels, yticklabels=labels, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.xlabel('Ground Truth')\n",
    "    plt.ylabel('Predicted')\n",
    "    \n",
    "    # alternative using sklearn plots\n",
    "    #plt.figure()\n",
    "    #from sklearn.metrics import ConfusionMatrixDisplay\n",
    "    #cm_display = ConfusionMatrixDisplay(cmat).plot()\n",
    "    \n",
    "    return pd.DataFrame([[f'TN = {tn} (TNR = {tnr:1.2%})', \n",
    "                                f'FP = {fp} (FPR = {fpr:1.2%})'], \n",
    "                         [f'FN = {fn} (FNR = {fnr:1.2%})', \n",
    "                                f'TP = {tp} (TPR = {tpr:1.2%})']],\n",
    "            index=['True 0(Non-Target)', 'True 1(Target)'], \n",
    "            columns=['Pred 0(Non-Target)', \n",
    "                            'Pred 1(Target)'])\n",
    "conf_matrix(y_test,y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba3aed",
   "metadata": {},
   "source": [
    "## Process the ROC curve and precision recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "y_score = clf.decision_function(X_test)\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=clf.classes_[1])\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)#.plot()\n",
    "\n",
    "\n",
    "# Precision Recall Display\n",
    "prec, recall, _ = precision_recall_curve(y_test, y_score,\n",
    "                                         pos_label=clf.classes_[1])\n",
    "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)#.plot()\n",
    "\n",
    "# Display them side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "roc_display.plot(ax=ax1)\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n",
    "ax1.legend(loc=\"lower right\")\n",
    "pr_display.plot(ax=ax2)\n",
    "\n",
    "\n",
    "if export_figures:\n",
    "    out_name = os.path.join(fig_folder, output_name + '_ROC')\n",
    "    fig.savefig(out_name, dpi=300, facecolor='w', edgecolor='w', bbox_inches='tight')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91533fb",
   "metadata": {},
   "source": [
    "## Signed R-Square plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a2cc9",
   "metadata": {},
   "source": [
    "### Use the function from Wyrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c95b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/bbci/wyrm/blob/master/wyrm/processing.py\n",
    "# Bastian Venthur for wyrm\n",
    "# Code initially from Benjamin Blankertz for bbci (Matlab)\n",
    "\n",
    "def calculate_signed_r_square_mne(epochs, classes=[0,1], classaxis=0, **kwargs):\n",
    "    \"\"\"Calculate the signed r**2 values.\n",
    "    This method calculates the signed r**2 values over the epochs of the\n",
    "    ``dat``.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : MNE epoched data\n",
    "    classes: list, optional \n",
    "        (either int index or str for the class name of the epoch))\n",
    "    classaxis : int, optional\n",
    "        the dimension containing epochs\n",
    "    Returns\n",
    "    -------\n",
    "    signed_r_square : ndarray\n",
    "        the signed r**2 values, signed_r_square has one axis less than\n",
    "        the ``dat`` parameter, the ``classaxis`` has been removed\n",
    "    Examples\n",
    "    --------\n",
    "    >>> dat.data.shape\n",
    "    (400, 100, 64)\n",
    "    >>> r = calculate_signed_r_square(dat)\n",
    "    >>> r.shape\n",
    "    (100, 64)\n",
    "    \"\"\"\n",
    "    # TODO: explain the algorithm in the docstring and add a reference\n",
    "    # to a paper.\n",
    "    # select class 0 and 1\n",
    "    # TODO: make class 0, 1 variables\n",
    "    fv1 = epochs[classes[0]]._data\n",
    "    fv2 = epochs[classes[1]]._data\n",
    "    # number of epochs per class\n",
    "    l1 = epochs[classes[0]]._data.shape[classaxis]\n",
    "    l2 = epochs[classes[1]]._data.shape[classaxis]\n",
    "    # calculate r-value (Benjamin approved!)\n",
    "    a = (fv1.mean(axis=classaxis) - fv2.mean(axis=classaxis)) * np.sqrt(l1 * l2)\n",
    "    b = epochs._data.std(axis=classaxis) * (l1 + l2)\n",
    "    r = a / b\n",
    "    # return signed r**2\n",
    "    return np.sign(r) * np.square(r)\n",
    "\n",
    "rsq = calculate_signed_r_square_mne(epochs, classes=['Target','NonTarget'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a0937",
   "metadata": {},
   "source": [
    "### make a pandas database to properly display electrodes and samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pandas database to properly display electrodes and samples\n",
    "fs = epochs.info['sfreq']\n",
    "x = np.float64(list(range(rsq.shape[1])))*(1000/fs)\n",
    "x = x.round(decimals=0).astype(np.int64) + np.int64(pre_epoch*1000)\n",
    "df_rsq = pd.DataFrame(rsq, columns=x, index=epochs.info['ch_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72663ac7",
   "metadata": {},
   "source": [
    "### Plot rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb8ac6",
   "metadata": {},
   "source": [
    "note that using a larger sampling rate will smooth this figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4beac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hm = sns.heatmap(df_rsq,linewidths=0,cmap=\"coolwarm\").set(title='Signed r-square maps Target vs Non-Target', xlabel='Time (ms)')\n",
    "\n",
    "if export_figures:\n",
    "    out_name = os.path.join(fig_folder, output_name + '_heatmap' )\n",
    "    plt.savefig(out_name, dpi=300, facecolor='w', edgecolor='w', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8339498",
   "metadata": {},
   "source": [
    "### Quickly Display a channel with max rsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = None  # <- specify the channel here or it will be selected automatically\n",
    "if picks is None:\n",
    "    ch_max, _ = np.where(rsq == np.max(rsq))\n",
    "    picks = epochs.info['ch_names'][int(ch_max)]\n",
    "\n",
    "#picks = [f'eeg{n}' for n in range(10, 15)]\n",
    "evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
    "               Target=list(epochs['Target'].iter_evoked()))\n",
    "axs = mne.viz.plot_compare_evokeds(evokeds, picks=picks)  # use combine='mean' if several electrode chosen in picks\n",
    "\n",
    "if export_figures:\n",
    "    out_name = os.path.join(fig_folder, output_name + '_best_channel')\n",
    "    axs[0].savefig(out_name, dpi=300, facecolor='w', edgecolor='w', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bdce3c",
   "metadata": {},
   "source": [
    "# Extract accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0834fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
