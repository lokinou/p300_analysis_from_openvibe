{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42c0d701-f04c-45c9-921d-c5c4ce488916",
   "metadata": {},
   "source": [
    "# P300 analysis from OpenVibe/BCI2000\n",
    "With lots of cool preprocessing features.\n",
    "source: [https://github.com/lokinou/p300_analysis_from_openvibe](https://github.com/lokinou/p300_analysis_from_openvibe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854cc76-57de-4274-ac1e-5a3de37b0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the line wit qt below to obtain separate plots\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68dfcc-ba47-488a-bbdf-2fbc1b9d54ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if packages are missing, uncomment and execute here or in anaconda prompt with p300mne env\n",
    "#!pip install \"git+https://github.com/nbara/python-meegkit\"\n",
    "#!pip install statsmodels pyriemann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cbf48-4e5e-4c0f-9654-c4f7dd5bf5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "# LDA\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e2a463-f342-477d-8a73-0ea2b4200857",
   "metadata": {},
   "source": [
    "## Define the analysis variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59758ce0-eb60-40c0-9ac2-3a8ea63920bb",
   "metadata": {},
   "source": [
    "if you don't know how to convert the .ov files, please check my [ov to gdf tutorial](https://github.com/lokinou/openvibe_to_gdf_tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34711c-6124-45ba-af26-acc2afb45241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the gdf files\n",
    "#data_dir=r\"C:\\BCI\\dev\\p300_analysis_from_openvibe\"\n",
    "data_dir=r\"./data_sample/bci2000\"\n",
    "data_type= None  # bci2000 or openvibe or None for autodetection\n",
    "\n",
    "# Define the electrodes here (for the provided sample file)\n",
    "#cname = ['Fz', 'FC1', 'FC2', 'C1', 'Cz', 'C2', 'P3', 'Pz', 'P4', 'Oz']\n",
    "cname = ['Fz', 'Cz', 'P3', 'Pz', 'P4', 'PO7', 'PO8', 'Oz']\n",
    "\n",
    "# Visual\n",
    "display_preprocessing_plots = False\n",
    "display_all_erp_plots = True\n",
    "export_figures = True\n",
    "fig_folder = './out'\n",
    "\n",
    "# Preprocessing\n",
    "apply_resample = True # in case the sampling rate is high (>=256Hz)\n",
    "resample_freq = 256 # Hz\n",
    "apply_infinite_reference = False  # rereferencing\n",
    "apply_ASR = False  # use Artifact Subspace Reconstruction (artifact removal)\n",
    "apply_CSD = False  # use Current Source Density (spatial filter)\n",
    "\n",
    "drop_bad_epochs = False\n",
    "reject_channels_full_of_artifacts = True\n",
    "reject_artifactual_epochs = reject_channels_full_of_artifacts and False # do not reject epochs if you dont reject channels or use CSD\n",
    "artifact_threshold = 100e-6\n",
    "ratio_tolerated_artifacts = 0.3  # if 30% of artifacts in 200ms windows, then the channel is rejected\n",
    "\n",
    "# ERP analysis parameters (values in sec)\n",
    "pre_epoch = -.200\n",
    "epoch_length = .800\n",
    "#isi = .0625\n",
    "#flash = .125\n",
    "\n",
    "\n",
    "# LDA\n",
    "resample_LDA = 32 # Hz\n",
    "nb_k_splits = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc9482-8f63-458c-b444-b5baf041f81c",
   "metadata": {},
   "source": [
    "## Load the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f3c36-db9f-4985-a6ab-ec2afe7e31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BCI2kReader import BCI2kReader as b2k\n",
    "from BCI2kReader import FileReader as f2k\n",
    "\n",
    "raws = []\n",
    "\n",
    "def extract_annotations(filename, verbose=False):\n",
    "    file = b2k.BCI2kReader(filename)\n",
    "    if verbose:\n",
    "        print(file.states)\n",
    "    target_states = np.squeeze(file.states['StimulusType'])\n",
    "    stimulus_states = np.squeeze(file.states['StimulusCode'])\n",
    "    if 'StimulusBegin' in file.states.keys():\n",
    "        stimulus_begin = np.squeeze(file.states['StimulusBegin'])\n",
    "    else:\n",
    "        stimulus_begin = np.squeeze(file.states['Flashing'])\n",
    "    fs = file.samplingrate\n",
    "    idx_targets = np.where(target_states)[0]\n",
    "    idx_codes = np.where(stimulus_states>0)[0]\n",
    "    idx_begin = np.where(stimulus_begin>0)[0]\n",
    "\n",
    "\n",
    "    # In BCI2000 states are maintained over different samples, we search here the differences of when the codes are > 0\n",
    "    groups = np.split(idx_codes, np.where(np.diff(idx_codes) != 1)[0]+1)\n",
    "    # we take the first sample where a difference can be found\n",
    "    code_change_idx = np.array([g[0] for g in groups])\n",
    "    #[idx_codes[idx] for idx in code_change_idx]\n",
    "    print('nb stimuli={}'.format(len(code_change_idx)))\n",
    "\n",
    "    # we intersect the target index list with the code change to find the onset of targets and non-targets\n",
    "    target_idx=np.intersect1d(code_change_idx,idx_targets)\n",
    "    print('nb targets={}'.format(len(target_idx)))\n",
    "    non_target_idx= np.setdiff1d(code_change_idx,idx_targets)\n",
    "\n",
    "    # Translating into MNE Annotations \n",
    "    # define the annotations from the recovered stimuli (in seconds)\n",
    "    sample_lengh = 1/fs\n",
    "    onsets = code_change_idx * sample_lengh\n",
    "    # define the descriptio\n",
    "    description = np.zeros(code_change_idx.shape, dtype=np.uint)\n",
    "    # index of targets in the list of stimuli onsets\n",
    "    description[np.searchsorted(code_change_idx, target_idx)] = 1\n",
    "    if display_preprocessing_plots:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(description[:100])\n",
    "        fig.suptitle('Targets(1) and non-targets(0) for 100 first stimuli')\n",
    "\n",
    "    # set minimum duration (should not matter)\n",
    "    duration = np.ones(code_change_idx.shape) * sample_lengh\n",
    "\n",
    "    return mne.Annotations(onset=onsets, duration=duration, description=description)\n",
    "\n",
    "def load_bci2k(filename_list):\n",
    "    raws = []\n",
    "    for fn in filename_list:\n",
    "        cname = None\n",
    "        with b2k.BCI2kReader(fn) as file:\n",
    "            \n",
    "            # Extract signals and states\n",
    "            print('opened')\n",
    "            eeg_data = file.signals\n",
    "            states = file.states\n",
    "            fs = file.samplingrate\n",
    "            nb_chan = eeg_data.shape[0]\n",
    "            #file.purge()\n",
    "\n",
    "            # Extract channel names\n",
    "            reader = f2k.bcistream(fn)\n",
    "            # actualize the parameters by including the defined channel names\n",
    "            if len(reader.params['ChannelNames']):\n",
    "                if cname != reader.params['ChannelNames']:\n",
    "                    cname = reader.params['ChannelNames']\n",
    "                    print('Actualized channel names to {}'.format(cname))\n",
    "\n",
    "            if cname is None:\n",
    "                cname = [str(ch_n) for ch_n in list(range(nb_chan))]\n",
    "                \n",
    "            # convert states into annotations\n",
    "            target_states = np.squeeze(file.states['StimulusTypeRes'])\n",
    "\n",
    "            info = mne.create_info(cname, fs, ch_types='eeg', verbose=None)\n",
    "            raw_array = mne.io.RawArray(eeg_data, info)\n",
    "            # Manually force the filename or mne complains\n",
    "            raw_array._filenames = [os.path.basename(fn)]\n",
    "            \n",
    "            annotations = extract_annotations(fn)\n",
    "            raw_array.set_annotations(annotations)\n",
    "            raws.append(raw_array)\n",
    "    return raws\n",
    "\n",
    "#fn = [\"./data_sample/bci2000\\Heide_einsteinBP_calibration4S001R01.dat\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b83f55-df25-417b-84ee-88b3876b61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(data_dir)\n",
    "fnames = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".gdf\"):\n",
    "        data_type = 'openvibe'\n",
    "        fnames.append(os.path.join(data_dir, file))\n",
    "        print(os.path.join(data_dir, file))\n",
    "    elif file.endswith(\".dat\"):\n",
    "        data_type = 'bci2000'\n",
    "        print(os.path.join(data_dir, file))\n",
    "        fnames.append(os.path.join(data_dir, file))\n",
    "        \n",
    "if data_type == 'openvibe':\n",
    "    # load and preprocess data ####################################################\n",
    "    raws = [mne.io.read_raw_gdf(f, preload=True) for f in fnames]\n",
    "elif data_type == 'bci2000':\n",
    "    raws = load_bci2k(fnames)\n",
    "raw = mne.concatenate_raws(raws)\n",
    "raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185c36c-61d3-469c-9d9f-d4253be5fbd4",
   "metadata": {},
   "source": [
    "Create a name for figures output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35bdcb-7c91-4750-9499-35216112d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = Path(raw._filenames[0]).stem\n",
    "if len(raw._filenames)>1:\n",
    "    output_name = output_name + '_{}_files'.format(len(raw._filenames))\n",
    "print('Figures will have the name: {}'.format(output_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f02e6-4902-42a3-94d5-03832fead9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_preprocessing_plots:\n",
    "    raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c7d941-a713-46a3-bbaf-eb4b3b8a233e",
   "metadata": {},
   "source": [
    "## Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84ae7ba-d5ad-42c8-95bd-ffcbfa3861ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_resample:\n",
    "    raw.resample(resample_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a007f-9a6f-4cac-b12b-815f08d30ea4",
   "metadata": {},
   "source": [
    "rename the electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b976d-222d-43f7-8afd-3bd173523477",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_chan = len(raw.info['ch_names'])\n",
    "nb_def_ch = len(cname)\n",
    "\n",
    "cname_map = dict(zip(raw.info['ch_names'], cname))\n",
    "# define channel types\n",
    "types = list(itertools.repeat('eeg', nb_def_ch))\n",
    "if len(raw.info['ch_names'])>nb_def_ch:\n",
    "    types.extend(list(itertools.repeat('misc', nb_def_ch)))\n",
    "type_map = dict(zip(cname, types))\n",
    "\n",
    "# rename and pick eeg\n",
    "raw.rename_channels(cname_map, allow_duplicates=False)\n",
    "raw.set_channel_types(type_map)\n",
    "raw.pick_types(eeg=True, misc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b8cba-2cf1-443b-acd0-99c02e79e3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4491e001-b570-4c2b-8477-77710f10d03a",
   "metadata": {},
   "source": [
    "Set the montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e5d81-89a0-449e-8975-43c9ded00a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "raw = raw.set_montage(montage, match_case=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817beb93-b12c-4384-b00d-3935ad8c2d85",
   "metadata": {},
   "source": [
    "Check whether there are bad channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7caaa-29a2-4fc9-a3fd-956b6f8dbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 50Hz power variance\n",
    "psd, freqs = mne.time_frequency.psd_welch(raw,verbose=True)\n",
    "power_50hz = psd[:,np.where(freqs ==60)]\n",
    "print('50Hz variance: {}'.format(mne.preprocessing.bads._find_outliers(power_50hz.squeeze(), threshold=3, max_iter=5, tail=0)))\n",
    "\n",
    "\n",
    "# using variance\n",
    "ch_var  = [np.var(raw._data[i,:]) for i in list(range(raw._data.shape[0]))]\n",
    "print('Variance: {}'.format(mne.preprocessing.bads._find_outliers(ch_var, threshold=3, max_iter=5, tail=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67428135-2324-4ed9-8174-197633e6d374",
   "metadata": {},
   "source": [
    "rereferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25efd75f-d11a-4cfd-a936-d71f00f114d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_infinite_reference:\n",
    "    raw.del_proj()  # remove our average reference projector first\n",
    "    sphere = mne.make_sphere_model('auto', 'auto', raw.info)\n",
    "    src = mne.setup_volume_source_space(sphere=sphere, exclude=30., pos=15.)\n",
    "    forward = mne.make_forward_solution(raw.info, trans=None, src=src, bem=sphere)\n",
    "    raw_rest = raw.copy().set_eeg_reference('REST', forward=forward)\n",
    "    \n",
    "    if display_preprocessing_plots:\n",
    "        for title, _raw in zip(['Original', 'REST (∞)'], [raw, raw_rest]):\n",
    "            fig = _raw.plot(n_channels=len(raw), scalings=dict(eeg=5e-5))\n",
    "            # make room for title\n",
    "            fig.subplots_adjust(top=0.9)\n",
    "            fig.suptitle('{} reference'.format(title), size='xx-large', weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb6e89-8a01-4995-a08a-b1008fc89a86",
   "metadata": {},
   "source": [
    "## Bandpass the signal\n",
    "Removes noise and drift from the EEG signal by applying a infinite impulse response (two-pass) filter between .5 and 40Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f0a63-9fb7-4c68-8593-6c6fcd2d1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.filter(.5, 40, fir_window='hann', method='iir')\n",
    "raw.notch_filter(50)  # removes 50Hz noise\n",
    "if display_preprocessing_plots:\n",
    "    raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321b03e-9731-4bdd-b930-8ff2217e162b",
   "metadata": {},
   "source": [
    "## Excluding of channels full of artifacts (muscular or disconnecting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23743c6-ca1f-49b4-a579-d47de37d3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Apply a variance based channel rejection if artifacts are present >30% of the time\n",
    "def detec_rej_channel(raw, duration=.2, overlap_duration=.1, threshold_eeg=artifact_threshold, reject_ratio=ratio_tolerated_artifacts):\n",
    "\n",
    "    epochs_rej = mne.make_fixed_length_epochs(raw,duration=duration, overlap=overlap_duration, preload=True)\n",
    "    epochs_rej._data.shape\n",
    "    diff = np.max(epochs_rej._data, axis=2) - np.min(epochs_rej._data, axis=2)\n",
    "\n",
    "    print(diff.shape)\n",
    "\n",
    "    rej = (diff>=threshold_eeg).astype(np.float64)\n",
    "    rel = sns.heatmap(rej)\n",
    "    rel.set(title='Detected artifacts per electrode and runs (white)')\n",
    "\n",
    "    # calculate ratio of rejected trials\n",
    "    ratios = np.sum(rej,axis=0) / rej.shape[0]\n",
    "    \n",
    "    ret = np.argwhere(ratios >= reject_ratio).tolist()\n",
    "    if len(ret)>0 and len(ret[0]):\n",
    "        print('Found {} channels with at least {}% {}s epochs > {} amplitude)'.format(len(ret), \n",
    "                                                                                              reject_ratio*100, duration,\n",
    "                                                                                      threshold_eeg))\n",
    "        return ret[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "if reject_channels_full_of_artifacts:\n",
    "    rej_ch = detec_rej_channel(raw)\n",
    "    if rej_ch is not None:\n",
    "        new_bads = [raw.info['ch_names'][ch] for ch in rej_ch]\n",
    "        raw.info['bads'].extend(new_bads)\n",
    "        raw.pick_types(eeg=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993550e-62ec-4b00-b44a-472a0e37d2d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Artifact Subspace Reconstruction fitting and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96109d3-d5c1-4533-8661-4446693de2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_ASR:\n",
    "    #!pip install meegkit pymanopt\n",
    "    from meegkit.asr import ASR\n",
    "    fs = int(raw.info[\"sfreq\"])  # sampling frequency\n",
    "    method='riemann'  # if error, use 'euclid'\n",
    "    window_s=.5  # .5 sec window of analysis\n",
    "    data_interval_s  = None # (begin, end) in sec of the training sample\n",
    "    estimator='lwf'  #leave blank if using euclidian mode \n",
    "\n",
    "    # define the ASR model using riemannian method\n",
    "    #asr_model = ASR(sfreq=fs, method=method, win_len=window_s, estimator=estimator)\n",
    "\n",
    "    # if failing (after trying twice. SVD error occurs for no reason sometimes)\n",
    "    asr_model = ASR(sfreq=fs, method=\"euclid\", win_len=window_s)\n",
    "\n",
    "    # The best would be to choose another recording during the same session to train the model without overfitting\n",
    "    data = raw._data  # the numpy array with data is stored in the _data variable\n",
    "\n",
    "    # Select a time interval for training data\n",
    "    train_idx = None\n",
    "    if data_interval_s is not None:\n",
    "        train_idx = np.arange(data_interval_s[0] * fs, data_interval_s[1] * fs, dtype=int)\n",
    "    # otherwise select the whole training set\n",
    "    else:\n",
    "        train_idx = np.arange(0, data.shape[1])\n",
    "\n",
    "    train_data = data[:, train_idx]\n",
    "    print('Training on samples of size {}'.format(train_data.shape))\n",
    "\n",
    "    # fir the ASR model with data intervals\n",
    "    _, sample_mask = asr_model.fit(train_data)\n",
    "    print('Model trained')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076752f7-71b0-4390-b301-9939e44a0eca",
   "metadata": {},
   "source": [
    "### Clean the current dataset\n",
    "Please check whether using this artifact filtering method increases signal to noise ratio rather than reducing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49e8ad-941c-42fd-92a4-7e369e8bec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_ASR:\n",
    "    clean =  asr_model.transform(raw._data)\n",
    "\n",
    "    display_window_s = 30  # \n",
    "\n",
    "    if display_preprocessing_plots:  #\n",
    "        data_p = raw._data[0:fs*display_window_s]  # reshape to (n_chans, n_times)\n",
    "        clean_p = clean[0:fs*display_window_s]\n",
    "\n",
    "        ###############################################################################\n",
    "        # Plot the results\n",
    "        # -----------------------------------------------------------------------------\n",
    "        #\n",
    "        # Data was trained on a 40s window from 5s to 45s onwards (gray filled area).\n",
    "        # The algorithm then removes portions of this data with high amplitude\n",
    "        # artifacts before running the calibration (hatched area = good).\n",
    "        nb_ch_disp = len(raw.info['ch_names'])\n",
    "        times = np.arange(data_p.shape[-1]) / fs\n",
    "        f, ax = plt.subplots(nb_ch_disp, sharex=True, figsize=(32, 16))\n",
    "        for i in range(nb_ch_disp):\n",
    "            # ax[i].fill_between(train_idx / fs, 0, 1, color='grey', alpha=.3,\n",
    "            #                   transform=ax[i].get_xaxis_transform(),\n",
    "            #                   label='calibration window')\n",
    "            # ax[i].fill_between(train_idx / fs, 0, 1, where=sample_mask.flat,\n",
    "            #                   transform=ax[i].get_xaxis_transform(),\n",
    "            #                   facecolor='none', hatch='...', edgecolor='k',\n",
    "            #                   label='selected window')\n",
    "            ax[i].plot(times, data_p[i], lw=.5, label='before ASR')\n",
    "            ax[i].plot(times, clean_p[i], label='after ASR', lw=.5)\n",
    "            # ax[i].plot(times, raw[i]-clean[i], label='Diff', lw=.5)\n",
    "            # ax[i].set_ylim([-50, 50])\n",
    "            ax[i].set_ylabel(f'ch{i}')\n",
    "            ax[i].set_yticks([])\n",
    "        ax[i].set_xlabel('Time (s)')\n",
    "        ax[0].legend(fontsize='small', bbox_to_anchor=(1.04, 1), borderaxespad=0)\n",
    "        plt.subplots_adjust(hspace=0, right=0.75)\n",
    "        plt.suptitle('Before/after ASR')\n",
    "        plt.show()\n",
    "    raw.data_ = clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb41f5-a8b9-444f-99ff-41ceea18868d",
   "metadata": {},
   "source": [
    "### Convert text annotations (i.e. unprocessed events) into events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00292fee-e0d2-4415-9d34-6ab54bd1ff6e",
   "metadata": {},
   "source": [
    "**Small but major hack to realign events due to conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630543f-eaa5-45dd-81ff-e07069786aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type=='openvibe':\n",
    "    print(\"Erroneous annotations: {}\".format(raw.annotations.description))\n",
    "    print('Note here that the first annotation is 0 or 1, this is an error and thus we shift the annotations to retrieve the correct timings')\n",
    "    raw.annotations.description = np.roll(raw.annotations.description, -1)\n",
    "    print(\"Corrected annotations: {}\".format(raw.annotations.description))\n",
    "\n",
    "    # in case you want to debug the issue, I left here a way to visualize them\n",
    "    # retrieving the list of annotations\n",
    "    import pprint\n",
    "    print(raw.annotations.to_data_frame())\n",
    "    df = raw.annotations.to_data_frame()\n",
    "    print('Displaying all annotations')\n",
    "    annot_codes = [np.int64(n) for n in np.unique(df['description'])]\n",
    "    df['description'] = df['description'].astype(int)\n",
    "\n",
    "    if False:\n",
    "        # to see and debug the fill list of annotations\n",
    "        import pandas as pd\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        #a = df[df['description'] != 33286]\n",
    "        #print(a)\n",
    "        print(df)\n",
    "        pd.set_option('display.max_rows', 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0eca1-add5-4a5b-99d2-ea7fb44a66ad",
   "metadata": {},
   "source": [
    "### Make a list of the annotations to check whether all stimuli can be found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6483e9-8bd7-4ba8-9712-fdc3da8eecf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "These annotations seem to relate to hex codes. OpenViBE definitions can be found on [OpenViBE's website](http://openvibe.inria.fr/stimulation-codes/). Let's parse the copypasted list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7db19-e91f-4f12-9a26-01b62809d5c2",
   "metadata": {},
   "source": [
    "Make a dataframe of the stimuli in common between both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee46ee6-cc49-430f-b1f3-c54751b539bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "if data_type=='openvibe':\n",
    "    tr_sim= ''\n",
    "    pat_extract= re.compile('^([^ ]+)[ ]+0x[0-9A-Fa-f]+[ \\/]+([0-9]+)')\n",
    "    #OVTK_GDF_125_Watt                                     0x585       //  1413\n",
    "    k_stim = []\n",
    "    k_stim_int = []\n",
    "    v_stim = []\n",
    "\n",
    "    # read and convert annotations\n",
    "    with open(r'.\\ov_stims.txt', 'r') as fd:\n",
    "        for line in fd.readlines():\n",
    "            m = pat_extract.match(line)\n",
    "            v, k = m.groups()\n",
    "            k_stim.append(k)\n",
    "            k_stim_int.append(int(k))\n",
    "            v_stim.append(v)\n",
    "\n",
    "    # format dict and list\n",
    "    stim_map = dict(zip(k_stim_int, v_stim))\n",
    "    stim_map_inv = dict(zip(v_stim, k_stim))\n",
    "\n",
    "    stim_tup = list(zip(k_stim_int, v_stim))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(stim_tup)\n",
    "    df.columns = ['coden', 'desc']\n",
    "    df[[c in annot_codes for c in df.coden]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c294bc40-0adc-49bd-822a-936e65d466b4",
   "metadata": {},
   "source": [
    "From this table, we could locate and save the codes for **Target and Non-Target** and give them the following values: target=1 and non-target=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff40c08-ed06-4464-83de-962916c84499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = 1, nontarget = 0\n",
    "target_map = None\n",
    "if data_type == 'openvibe':\n",
    "    target_map = {'33286':0, '33285':1}\n",
    "elif data_type == \"bci2000\":\n",
    "    target_map = {'0':0, '1':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d9672-0c91-46c7-9aeb-3bd09c1eb592",
   "metadata": {},
   "source": [
    "Then we can convert annotations into events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573862f-eb94-47ca-bfae-fd7c245dd794",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, _ = mne.events_from_annotations(raw, event_id=target_map)\n",
    "print(\"Found {} events\".format(len(events[:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f89ebc-42cf-44e5-9bc3-269da549ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7f550-9792-48fa-91c8-d39382aed2fd",
   "metadata": {},
   "source": [
    "### Pick the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4551f706-96b2-4b1b-b015-ab394cb4e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick all channels\n",
    "picks = mne.pick_channels(raw.info[\"ch_names\"], include=[])\n",
    "picks\n",
    "raw.plot_sensors(show_names=True)\n",
    "fig = raw.plot_sensors('3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d17f5c-4f50-43c7-ba6e-4689fd91c1bc",
   "metadata": {},
   "source": [
    "## Epoching from events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017b448-1207-4ae9-b2db-db9e1ac1afec",
   "metadata": {},
   "source": [
    "Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a4918-1946-41e6-aaae-4703802f6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "events[:, 0]\n",
    "a = np.array(events[:, 0])\n",
    "dups = [item for item, count in Counter(a).items() if count > 1]\n",
    "if dups:\n",
    "    print(\"WARNING: Duplicate found at sample(s) {}\".format(dups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c161d5-833b-468c-b897-7e3ed29bac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_ids = dict(NonTarget=0, Target=1) \n",
    "#isi = isi\n",
    "#flash = flash\n",
    "pre_epoch = pre_epoch\n",
    "epoch_length = epoch_length\n",
    "\n",
    "\n",
    "# epoching function\n",
    "epochs = mne.Epochs(raw, events, baseline=(-.2, 0), event_id=event_ids, tmin=pre_epoch, tmax=epoch_length, event_repeated='drop', picks = ['eeg', 'csd'],\n",
    "                    preload=True)\n",
    "\n",
    "# if there is any delay,\n",
    "#epochs.shift_time(-isi, relative=True)\n",
    "if display_preprocessing_plots:\n",
    "    fig = epochs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1f4c5-ecde-492e-897d-c59c4dbb628b",
   "metadata": {},
   "source": [
    "### Making a cross correlation plot between the electrodes to see how channels relate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532ba92-d88e-4634-8d9b-375a3b20dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.corrcoef(raw._data)\n",
    "fig = plt.figure()\n",
    "hm = sns.heatmap(m,linewidths=0,cmap=\"YlGnBu\").set(title='Cross correlation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e98b0-83f6-4b4f-8f78-0679381217ff",
   "metadata": {},
   "source": [
    "### Epoch rejection\n",
    "Please filter out channels before epochs. A problematic channel can discard the whole recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c16c27-dd90-411a-8e8f-bc938475d250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if reject_artifactual_epochs:\n",
    "    reject_criteria = dict(eeg=100e-6)  # 100 µV  #eog=200e-6)\n",
    "    _ = epochs.drop_bad(reject=reject_criteria)\n",
    "    if display_preprocessing_plots:\n",
    "        epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e178d4-9a5c-41bb-8be7-e230f8c69964",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Apply current source density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfda66-0390-42b7-8b34-d70227c7e3ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if apply_CSD:\n",
    "    epochs_csd = mne.preprocessing.compute_current_source_density(epochs)\n",
    "    epochs = epochs_csd\n",
    "    if display_preprocessing_plots:\n",
    "        epochs_csd.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd394a47-c470-41cd-ac5d-9c7d6b88941c",
   "metadata": {},
   "source": [
    "### Average the epochs of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ee82c-fff7-46c7-8b8d-ad958091ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_nt = epochs['NonTarget'].average()\n",
    "l_target = epochs['Target'].average()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfccfc-2843-4cde-920a-01f6aff53afe",
   "metadata": {},
   "source": [
    "target and non target signal plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493dee44-4d4d-4caf-b5c9-92363ce6e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_all_erp_plots:\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    fig1 = l_target.plot(spatial_colors=True, axes=ax[0], show=False)\n",
    "    fig2 = l_nt.plot(spatial_colors=True, axes=ax[1], show=False)\n",
    "    # Add title\n",
    "    fig.suptitle(\"Target(top) - Non-Target(bottom)\")\n",
    "    # Fix font spacing\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3338816-30e1-4b71-a1e9-46942371f7fc",
   "metadata": {},
   "source": [
    "target and non target signal topomaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ccd337-091a-4146-97ad-a1891b0ddfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if display_all_erp_plots:\n",
    "    spec_kw = dict(width_ratios=[1,1,1,.15], wspace=0.5,\n",
    "                   hspace=0.5,height_ratios=[1,1])\n",
    "                             #hspace=0.5, height_ratios=[1, 2])\n",
    "\n",
    "    fig, ax = plt.subplots(2, 4, gridspec_kw=spec_kw)\n",
    "    l_target.plot_topomap(times=[0, 0.18, 0.4], average=0.05, axes=ax[0,:], show=False)\n",
    "    l_nt.plot_topomap(times=[0, 0.18, 0.4], average=0.05, axes=ax[1,:], show=False)\n",
    "    fig.suptitle(\"Target(top) - Non-Target(bottom)\")\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5082021-4045-4275-85dd-4c5d564e1b21",
   "metadata": {},
   "source": [
    "joint plot (of the two former graphs). Plase not that Y scales differ between plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94eae2-52ac-441d-9e1c-2f1fdf928f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_target.plot_joint()\n",
    "plt.gcf().canvas.set_window_title('Target joint plot')\n",
    "l_nt.plot_joint()\n",
    "plt.gcf().canvas.set_window_title('Non-Target joint plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4947b44f-1766-4298-bfb1-60fcc33f14fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Average plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ab65e-8ad6-436f-bc21-63028d41cbb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if display_all_erp_plots:\n",
    "    evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
    "                   Target=list(epochs['Target'].iter_evoked()))\n",
    "    #picks = [f'eeg{n}' for n in range(10, 15)]\n",
    "    mne.viz.plot_compare_evokeds(evokeds, picks=picks, combine='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a7ebd-2adf-42b6-b19d-39f2a38550f3",
   "metadata": {},
   "source": [
    "### Target vs NonTarget Erps per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179a42f-28c0-4e41-9367-698adab1eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_chans = epochs['Target']._data.shape[1]\n",
    "splt_width = int(np.floor(np.sqrt(1.0*nb_chans+1)))  # adding an extra plot with all channels combined at the end\n",
    "splt_height = splt_width if splt_width * splt_width >= nb_chans+1 else splt_width+1\n",
    "if splt_height * splt_width < nb_chans+1:\n",
    "    splt_height += 1\n",
    "fig, ax = plt.subplots(splt_height,splt_width)\n",
    "\n",
    "evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
    "               Target=list(epochs['Target'].iter_evoked()))\n",
    "#picks = [f'eeg{n}' for n in range(10, 15)]\n",
    "\n",
    "shape_epochs = epochs['Target']._data.shape\n",
    "for ch_idx in range(nb_chans):\n",
    "    print('plotting channel {}'.format(ch_idx+1))\n",
    "    mne.viz.plot_compare_evokeds(evokeds,picks=[epochs.info['ch_names'][ch_idx]],\n",
    "                                 legend=False,\n",
    "                                 axes=ax[ch_idx//splt_width, ch_idx%splt_width], show=False)\n",
    "    #plt.show(block=False)\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=.5)\n",
    "    #plt.pause(.1)\n",
    "print('plotting averaged channels')\n",
    "axs = mne.viz.plot_compare_evokeds(evokeds, picks=picks, combine='mean',\n",
    "                             legend=True,\n",
    "                             axes=ax[-1,-1], show=False)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace=.5)\n",
    "plt.show()\n",
    "print(\"Please note that this plot is optimized for higher resolution and has the legend overlapping the average\")\n",
    "\n",
    "if export_figures:\n",
    "    out_name = os.path.join(fig_folder, output_name + '_ERPs')\n",
    "    axs[0].savefig(out_name, dpi=300, facecolor='w', edgecolor='w', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38bb7fc-4c02-4e77-baba-ba3926de6bda",
   "metadata": {},
   "source": [
    "### Display epoch at Cz and Pz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba5216-016d-4311-b5d3-d5d6017ed004",
   "metadata": {},
   "source": [
    "### Display single epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251bbf91-a066-4bd6-9be7-b6b736861f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_all_erp_plots:\n",
    "    epochs['Target'].plot_image(combine='mean')\n",
    "    plt.gcf().canvas.set_window_title('Target')\n",
    "    epochs['NonTarget'].plot_image(combine='mean')\n",
    "    plt.gcf().canvas.set_window_title('Non-Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47492b06-19df-4956-8c28-3b1639b746e8",
   "metadata": {},
   "source": [
    "### Same plot but channel wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b4c74-ff83-4be3-a33f-5bd947601797",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_electrodes = dict(eeg='EEG') if not apply_CSD else dict(csd='CSD')\n",
    "\n",
    "if display_all_erp_plots:\n",
    "    for ch_type, title in dict_electrodes.items():\n",
    "        layout = mne.channels.find_layout(epochs.info, ch_type=ch_type)\n",
    "        epochs['Target'].plot_topo_image(layout=layout, fig_facecolor='w',\n",
    "                                                font_color='k', title=title+' Target Trial x time amplitude')\n",
    "        epochs['NonTarget'].plot_topo_image(layout=layout, fig_facecolor='w',\n",
    "                                                font_color='k', title=title+' Non-Target Trial x time amplitude')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057d4cc-bd24-4ed5-ba78-98cc82a98cbb",
   "metadata": {},
   "source": [
    "# Assess ERP classificaiton accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0631ea1-0c0e-421e-94d4-aa8e6578ef27",
   "metadata": {},
   "source": [
    "resample the signal, we don't need that much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25423f3-2d88-4ecf-8641-1d4024392432",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fs = resample_LDA #\n",
    "epochs_resampled = epochs.copy().resample(new_fs)\n",
    "print('resampling to {}Hz'.format(new_fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f9e43-3ee9-4291-b74b-abd39b7678be",
   "metadata": {},
   "source": [
    "modify the data matrix to be properly assessed via LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17b74d-2527-4f81-bbdf-52694b08ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X = epochs_resampled._data[:,1,:]  # input data at CZ (TODO:flatten all electrodes)\n",
    "X = epochs_resampled._data[:,:,:]  # input data at CZ (TODO:flatten all electrodes)\n",
    "y = epochs_resampled.events[:,2]  # ground truth\n",
    "\n",
    "# remove the information \n",
    "    \n",
    "#mne.stats.permutation_t_test()\n",
    "print('Data shape from MNE {}'.format(X.shape))\n",
    "X = np.moveaxis(X,1,-1)\n",
    "print('new data shape with sampling prioritized over channels {}'.format(X.shape))\n",
    "X = X.reshape([X.shape[0],X.shape[1]*X.shape[2]],order='C')\n",
    "print('Shape for K-fold LDA {}'.format(X.shape))\n",
    "\n",
    "# Think about splitting training sample and test samples\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75edfd-6959-4d93-a10a-845cc1790a92",
   "metadata": {},
   "source": [
    "### Compute k-fold LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b038c6-bde9-4cb1-933c-f169ed9c7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearDiscriminantAnalysis(solver='lsqr',shrinkage='auto')\n",
    "kf = KFold(n_splits=nb_k_splits)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_f, X_test_f = X[train_index], X[test_index]\n",
    "    y_train_f, y_test_f = y[train_index], y[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    kscore = clf.score(X_test_f,y_test_f)\n",
    "    y_pred = clf.predict(X_test_f)\n",
    "    print('fold score: {}'.format(np.round(kscore, decimals=3)))\n",
    "    accuracy.append(kscore)\n",
    "print('Average accuracy {}-Fold = {}'.format(kf.get_n_splits(X), np.round(np.mean(accuracy), decimals=2)))\n",
    "\n",
    "# using the training/validate samples\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Score training-validation {}'.format(np.round(clf.score(X_test,y_test), decimals=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d4d42-36f0-4544-a4aa-8fbd58344a8e",
   "metadata": {},
   "source": [
    "### Display train-test LDA classification in a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa85d92-698a-4022-a571-44ab4a53e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conf_matrix(y,pred):\n",
    "    cmat = metrics.confusion_matrix(y, pred)\n",
    "    cmat_norm = metrics.confusion_matrix(y, pred, \n",
    "            normalize='true')\n",
    "    ((tn, fp), (fn, tp)) = cmat\n",
    "    ((tnr,fpr),(fnr,tpr)) = cmat_norm\n",
    "    \n",
    "    plt.figure()\n",
    "    labels = ['Non-Target', 'Target']\n",
    "    sns.heatmap(cmat, xticklabels=labels, yticklabels=labels, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.xlabel('Ground Truth')\n",
    "    plt.ylabel('Predicted')\n",
    "    \n",
    "    # alternative using sklearn plots\n",
    "    #plt.figure()\n",
    "    #from sklearn.metrics import ConfusionMatrixDisplay\n",
    "    #cm_display = ConfusionMatrixDisplay(cmat).plot()\n",
    "    \n",
    "    return pd.DataFrame([[f'TN = {tn} (TNR = {tnr:1.2%})', \n",
    "                                f'FP = {fp} (FPR = {fpr:1.2%})'], \n",
    "                         [f'FN = {fn} (FNR = {fnr:1.2%})', \n",
    "                                f'TP = {tp} (TPR = {tpr:1.2%})']],\n",
    "            index=['True 0(Non-Target)', 'True 1(Target)'], \n",
    "            columns=['Pred 0(Non-Target)', \n",
    "                            'Pred 1(Target)'])\n",
    "conf_matrix(y_test,y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5556d31-1e2d-48e7-9c09-a04ad50be99f",
   "metadata": {},
   "source": [
    "## Process the ROC curve and precision recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed36cc0-5a36-49b2-849a-cfb7de3b4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "y_score = clf.decision_function(X_test)\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=clf.classes_[1])\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)#.plot()\n",
    "\n",
    "\n",
    "# Precision Recall Display\n",
    "prec, recall, _ = precision_recall_curve(y_test, y_score,\n",
    "                                         pos_label=clf.classes_[1])\n",
    "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)#.plot()\n",
    "\n",
    "# Display them side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "roc_display.plot(ax=ax1)\n",
    "pr_display.plot(ax=ax2)\n",
    "\n",
    "\n",
    "if export_figures:\n",
    "    out_name = os.path.join(fig_folder, output_name + '_ROC')\n",
    "    plt.savefig(out_name, dpi=300, facecolor='w', edgecolor='w', bbox_inches='tight')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2bdd5c-6a9f-47c8-8d46-bc33b21eef87",
   "metadata": {},
   "source": [
    "## Signed R-Square plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eba796-e40c-45e2-b2d8-1ef78d83e335",
   "metadata": {},
   "source": [
    "### Use the function from Wyrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe797b-70e3-4901-a8c5-ff59c3067789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/bbci/wyrm/blob/master/wyrm/processing.py\n",
    "# Bastian Venthur for wyrm\n",
    "# Code initially from Benjamin Blankertz for bbci (Matlab)\n",
    "\n",
    "def calculate_signed_r_square_mne(epochs, classes=[0,1], classaxis=0, **kwargs):\n",
    "    \"\"\"Calculate the signed r**2 values.\n",
    "    This method calculates the signed r**2 values over the epochs of the\n",
    "    ``dat``.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : MNE epoched data\n",
    "    classes: list, optional \n",
    "        (either int index or str for the class name of the epoch))\n",
    "    classaxis : int, optional\n",
    "        the dimension containing epochs\n",
    "    Returns\n",
    "    -------\n",
    "    signed_r_square : ndarray\n",
    "        the signed r**2 values, signed_r_square has one axis less than\n",
    "        the ``dat`` parameter, the ``classaxis`` has been removed\n",
    "    Examples\n",
    "    --------\n",
    "    >>> dat.data.shape\n",
    "    (400, 100, 64)\n",
    "    >>> r = calculate_signed_r_square(dat)\n",
    "    >>> r.shape\n",
    "    (100, 64)\n",
    "    \"\"\"\n",
    "    # TODO: explain the algorithm in the docstring and add a reference\n",
    "    # to a paper.\n",
    "    # select class 0 and 1\n",
    "    # TODO: make class 0, 1 variables\n",
    "    fv1 = epochs[classes[0]]._data\n",
    "    fv2 = epochs[classes[1]]._data\n",
    "    # number of epochs per class\n",
    "    l1 = epochs[classes[0]]._data.shape[classaxis]\n",
    "    l2 = epochs[classes[1]]._data.shape[classaxis]\n",
    "    # calculate r-value (Benjamin approved!)\n",
    "    a = (fv1.mean(axis=classaxis) - fv2.mean(axis=classaxis)) * np.sqrt(l1 * l2)\n",
    "    b = epochs._data.std(axis=classaxis) * (l1 + l2)\n",
    "    r = a / b\n",
    "    # return signed r**2\n",
    "    return np.sign(r) * np.square(r)\n",
    "\n",
    "rsq = calculate_signed_r_square_mne(epochs, classes=['Target','NonTarget'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35684ec4-f1ce-44df-98b1-d9b1f1bcef14",
   "metadata": {},
   "source": [
    "### make a pandas database to properly display electrodes and samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65830b83-8ad1-4e4a-8f2b-eb58bf1fc198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pandas database to properly display electrodes and samples\n",
    "fs = epochs.info['sfreq']\n",
    "x = np.float64(list(range(rsq.shape[1])))*(1000/fs)\n",
    "x = x.round(decimals=0).astype(np.int64) + np.int64(pre_epoch*1000)\n",
    "df_rsq = pd.DataFrame(rsq, columns=x, index=epochs.info['ch_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74155c1b-e68c-42b1-a3a5-148d8461cde4",
   "metadata": {},
   "source": [
    "### Plot rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc833c-aaa5-475a-95be-804fb8939ea9",
   "metadata": {},
   "source": [
    "note that using a larger sampling rate will smooth this figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33288a25-2999-4b1e-b0a9-bb5ff397ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hm = sns.heatmap(df_rsq,linewidths=0,cmap=\"coolwarm\").set(title='Signed r-square maps Target vs Non-Target', xlabel='Time (ms)')\n",
    "\n",
    "if export_figures:\n",
    "    out_name = os.path.join(fig_folder, output_name + '_heatmap' )\n",
    "    plt.savefig(out_name, dpi=300, facecolor='w', edgecolor='w', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab28c2d2-c374-4877-b98e-6789d868390a",
   "metadata": {},
   "source": [
    "### Quickly Display a channel with max rsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae3c30-6858-4e58-9c54-f3410dc7d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = None  # <- specify the channel here or it will be selected automatically\n",
    "if picks is None:\n",
    "    ch_max, _ = np.where(rsq == np.max(rsq))\n",
    "    picks = epochs.info['ch_names'][int(ch_max)]\n",
    "\n",
    "#picks = [f'eeg{n}' for n in range(10, 15)]\n",
    "evokeds = dict(NonTarget=list(epochs['NonTarget'].iter_evoked()), \n",
    "               Target=list(epochs['Target'].iter_evoked()))\n",
    "axs = mne.viz.plot_compare_evokeds(evokeds, picks=picks)  # use combine='mean' if several electrode chosen in picks\n",
    "\n",
    "if export_figures:\n",
    "    out_name = os.path.join(fig_folder, output_name + '_best_channel')\n",
    "    axs[0].savefig(out_name, dpi=300, facecolor='w', edgecolor='w', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a4c77-b66b-4000-8ce8-86f2486dfd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58424688-4398-436d-b238-1ed502bcd93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
